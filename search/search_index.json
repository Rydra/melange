{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The spice must flow Melange is a python library/framework that abstracts a lot of the boilerplate that is usually required to implement a messaging infrastructure (commonly used to create distributed architectures and interact with microservices architectures). Out of the box Melange supports Amazon SQS, SNS and RabbitMQ, though the library is designed to be extensible, so that you can use it with your own messaging infrastructure, should you choose so. The interface this library offers is very clean and tries to tightly follow the best practices from Vaughn Vernon's book Implementing Domain-Driven Design as well as the recommended design patterns when dealing with messaging on distributed architectures. Installing pip install melange Documentation Full documentation is available at https://rydra.github.io/melange/ Examples The code base features several full-fledged examples that covers some complex use cases: Saga choreography in action Payment service Why the name 'Melange' The name \"Melange\" is a reference to the drug-spice from the sci-fi book saga \"Dune\", a spice which is only generated in a single planet in the universe (planet Dune) and every human depends on it. If the spice flows, then the spice can be controlled. He who controls the spice, controls the universe. The spice must flow. The analogy can be very well made on Events in a distributed architecture :) Contributing We're open to contributions and opinions! Project Links Docs: https://rydra.github.io/melange License MIT licensed. See the bundled LICENSE file for more details. Logo Nature Vectors by Vecteezy","title":"Melange"},{"location":"#installing","text":"pip install melange","title":"Installing"},{"location":"#documentation","text":"Full documentation is available at https://rydra.github.io/melange/","title":"Documentation"},{"location":"#examples","text":"The code base features several full-fledged examples that covers some complex use cases: Saga choreography in action Payment service","title":"Examples"},{"location":"#why-the-name-melange","text":"The name \"Melange\" is a reference to the drug-spice from the sci-fi book saga \"Dune\", a spice which is only generated in a single planet in the universe (planet Dune) and every human depends on it. If the spice flows, then the spice can be controlled. He who controls the spice, controls the universe. The spice must flow. The analogy can be very well made on Events in a distributed architecture :)","title":"Why the name 'Melange'"},{"location":"#contributing","text":"We're open to contributions and opinions!","title":"Contributing"},{"location":"#project-links","text":"Docs: https://rydra.github.io/melange","title":"Project Links"},{"location":"#license","text":"MIT licensed. See the bundled LICENSE file for more details. Logo Nature Vectors by Vecteezy","title":"License"},{"location":"advanced-topics/","text":"Advanced Topics Registering the MessagingBackend globally To instantiate a publishers or a consumer, you need to pass a MessagingBackend as a constructor argument. Depending on the circumstances, however, this might feel repetitive. As an alternative, you could use the singleton BackendManager and register a backend for global usage in your initialization code: BackendManager () . use_backend ( SQSBackend ()) From that point forward, any instantiation of a Publisher or Consumer does not need a backend as an argument anymore. Revisiting one of the recurring examples of this documentation, we could use the BackendManager like this. from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.backends.sqs.backend_manager import BackendManager from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () BackendManager () . use_backend ( backend ) publisher = QueuePublisher ( serializer ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) Notice that we are not passing the backend now as a parameter when creating the QueuePublisher object, since it will retrieve it from the BackendManager. NOTE: Use the BackendManager with caution though. Singletons are regarded sometimes as an antipattern depending on the situation, and dependency injection is usually regarded as a cleaner solution to construct objects. Message de-duplication Distributed architectures are hard, complex and come with a good deal of burdens, but they are required to achieve levels of scalability and isolation harder to achieve on monolithic architectures. One of this issues is the possibility of of the same message being received twice by the listeners. Network failures, application crashes, etc... can cause this issue which, if not though or left undealt can cause your system to be out of sync and run in an inconsistent state. This is why you need to take measures. One of this measures is to, simply, write your listeners to be idempotent . This means that it does not matter how many times a listener is called, the result will be the same and it won't impact or leave the system into an inconsistent state. However, sometimes writing idempotent code is just not possible. You require message deduplication to account for this and ensure that a message won't be sent twice. You could use Amazon SQS FIFO Queues which they say they provide this message deduplication, though not only FIFO queues are more expensive than standard ones, but exactly-once delivery is just impossible . In Melange we have accounted for this with a Redis cache that will control that no message is delivered twice. In order for this to work you have to provide the following environment variables as configuration so that Melange can connect to your Redis database: ENVIRONMENT VARIABLE NAME Default Description CACHE_REDIS_HOST localhost The host of your Redis CACHE_REDIS_PORT 6379 The port of your Redis CACHE_REDIS_DB 0 The DB to use for your Redis CACHE_REDIS_PASSWORD The password of your Redis CACHE_NAMESPACE SimpleCache You can provide a namespace so that values created by Melange do not collide with each other If Melange is unable to connect to your Redis it will function normally but you won't enjoy the benefits of ensuring message deduplication, which may lead your distributed application in an inconsitent state. You're warned :).","title":"Advanced topics"},{"location":"advanced-topics/#advanced-topics","text":"","title":"Advanced Topics"},{"location":"advanced-topics/#registering-the-messagingbackend-globally","text":"To instantiate a publishers or a consumer, you need to pass a MessagingBackend as a constructor argument. Depending on the circumstances, however, this might feel repetitive. As an alternative, you could use the singleton BackendManager and register a backend for global usage in your initialization code: BackendManager () . use_backend ( SQSBackend ()) From that point forward, any instantiation of a Publisher or Consumer does not need a backend as an argument anymore. Revisiting one of the recurring examples of this documentation, we could use the BackendManager like this. from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.backends.sqs.backend_manager import BackendManager from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () BackendManager () . use_backend ( backend ) publisher = QueuePublisher ( serializer ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) Notice that we are not passing the backend now as a parameter when creating the QueuePublisher object, since it will retrieve it from the BackendManager. NOTE: Use the BackendManager with caution though. Singletons are regarded sometimes as an antipattern depending on the situation, and dependency injection is usually regarded as a cleaner solution to construct objects.","title":"Registering the MessagingBackend globally"},{"location":"advanced-topics/#message-de-duplication","text":"Distributed architectures are hard, complex and come with a good deal of burdens, but they are required to achieve levels of scalability and isolation harder to achieve on monolithic architectures. One of this issues is the possibility of of the same message being received twice by the listeners. Network failures, application crashes, etc... can cause this issue which, if not though or left undealt can cause your system to be out of sync and run in an inconsistent state. This is why you need to take measures. One of this measures is to, simply, write your listeners to be idempotent . This means that it does not matter how many times a listener is called, the result will be the same and it won't impact or leave the system into an inconsistent state. However, sometimes writing idempotent code is just not possible. You require message deduplication to account for this and ensure that a message won't be sent twice. You could use Amazon SQS FIFO Queues which they say they provide this message deduplication, though not only FIFO queues are more expensive than standard ones, but exactly-once delivery is just impossible . In Melange we have accounted for this with a Redis cache that will control that no message is delivered twice. In order for this to work you have to provide the following environment variables as configuration so that Melange can connect to your Redis database: ENVIRONMENT VARIABLE NAME Default Description CACHE_REDIS_HOST localhost The host of your Redis CACHE_REDIS_PORT 6379 The port of your Redis CACHE_REDIS_DB 0 The DB to use for your Redis CACHE_REDIS_PASSWORD The password of your Redis CACHE_NAMESPACE SimpleCache You can provide a namespace so that values created by Melange do not collide with each other If Melange is unable to connect to your Redis it will function normally but you won't enjoy the benefits of ensuring message deduplication, which may lead your distributed application in an inconsitent state. You're warned :).","title":"Message de-duplication"},{"location":"api-reference/","text":"API reference Publishers TopicPublisher Some documentation here is in order Source code in melange/publishers.py class TopicPublisher : \"\"\" Some documentation here is in order \"\"\" def __init__ ( self , message_serializer : MessageSerializer , backend : Optional [ MessagingBackend ] = None , ) -> None : self . _backend = backend or BackendManager () . get_backend () self . message_serializer = message_serializer def publish ( self , topic_name : str , data : Any , ** extra_attributes : Any ) -> bool : topic = self . _backend . declare_topic ( topic_name ) content = self . message_serializer . serialize ( data ) manifest = self . message_serializer . manifest ( data ) self . _backend . publish ( content , topic , event_type_name = manifest , extra_attributes = extra_attributes , ) return True Consumers SingleDispatchConsumer ( Consumer , SingleDispatch ) This class can consume events from a queue and pass them to a processor Source code in melange/consumers.py class SingleDispatchConsumer ( Consumer , SingleDispatch ): \"\"\" This class can consume events from a queue and pass them to a processor \"\"\" def process ( self , message : Any , ** kwargs : Any ) -> None : self . _process ( message ) @singledispatch def _process ( self , message : Any ) -> None : \"\"\"Event should be an instance of DomainEvent\"\"\" pass def listens_to ( self ) -> List [ str ]: accepted_events = filter ( lambda t : t is not object , self . _process . registry ) return lmap ( lambda ev_type : ev_type . __name__ , accepted_events ) def accepts ( self , manifest : Optional [ str ]) -> bool : \"\"\" Default implementation. You can override this if you want, for example, to accept any manifest and not only the type of classes you listen (useful to override in the face of subclasses) \"\"\" return not self . listens_to () or manifest in self . listens_to () accepts ( self , manifest ) Default implementation. You can override this if you want, for example, to accept any manifest and not only the type of classes you listen (useful to override in the face of subclasses) Source code in melange/consumers.py def accepts ( self , manifest : Optional [ str ]) -> bool : \"\"\" Default implementation. You can override this if you want, for example, to accept any manifest and not only the type of classes you listen (useful to override in the face of subclasses) \"\"\" return not self . listens_to () or manifest in self . listens_to () Messaging Backend Factory Serializers MessageSerializer ( Generic ) Base interface to inherit for all the serializers of the platform Source code in melange/serializers/interfaces.py class MessageSerializer ( Generic [ T ]): \"\"\" Base interface to inherit for all the serializers of the platform \"\"\" def manifest ( self , data : T ) -> str : return \"\" def deserialize ( self , data : str , manifest : Optional [ str ] = None ) -> T : pass def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass serialize ( self , data ) Serializes and object to a string representation Source code in melange/serializers/interfaces.py def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass JsonSerializer ( MessageSerializer ) Source code in melange/serializers/json.py class JsonSerializer ( MessageSerializer [ Dict ]): def manifest ( self , data : Dict ) -> str : return \"json\" def deserialize ( self , serialized_data : str , manifest : Optional [ str ] = None ) -> Dict : data = json . loads ( serialized_data ) return data def serialize ( self , data : Dict ) -> str : return json . dumps ( data ) serialize ( self , data ) Serializes and object to a string representation Source code in melange/serializers/json.py def serialize ( self , data : Dict ) -> str : return json . dumps ( data ) PickleSerializer ( MessageSerializer ) Serializes DomainEvents with pickle Source code in melange/serializers/pickle.py class PickleSerializer ( MessageSerializer [ DomainEvent ]): \"\"\" Serializes DomainEvents with pickle \"\"\" def manifest ( self , data : DomainEvent ) -> str : return data . __class__ . __qualname__ def deserialize ( self , data : str , manifest : Optional [ str ] = None ) -> DomainEvent : return pickle . loads ( codecs . decode ( data . encode (), \"base64\" )) def serialize ( self , data : DomainEvent ) -> str : return codecs . encode ( pickle . dumps ( data ), \"base64\" ) . decode () serialize ( self , data ) Serializes and object to a string representation Source code in melange/serializers/pickle.py def serialize ( self , data : DomainEvent ) -> str : return codecs . encode ( pickle . dumps ( data ), \"base64\" ) . decode () Messaging Backends MessagingBackend Source code in melange/backends/interfaces.py class MessagingBackend : def __init__ ( self ) -> None : self . _finalizer = weakref . finalize ( self , self . close_connection ) def declare_topic ( self , topic_name : str ) -> Topic : \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required \"\"\" raise NotImplementedError def get_queue ( self , queue_name : str ) -> Queue : \"\"\" Gets the queue with the name `queue_name`. Args: queue_name: the name of the queue to retrieve Returns: A `Queue` object that represents the created the queue \"\"\" raise NotImplementedError def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : Optional [ str ] = None , ** kwargs : Any ) -> Tuple [ Queue , Optional [ Queue ]]: \"\"\" Creates a queue named `queue_name` if it does not exist. with default settings. Args: queue_name: the name of the queue to create *topics_to_bind: if provided, creates all these topics and subscribes the created queue to them dead_letter_queue_name: if provided, create a dead letter queue attached to the created `queue_name`. **kwargs: Returns: A tuple with the created queue and the dead letter queue (if applies) \"\"\" raise NotImplementedError def retrieve_messages ( self , queue : Queue , attempt_id : Optional [ str ] = None ) -> List [ Message ]: \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Optional [ Dict ] = None , ) -> None : \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError def queue_publish ( self , content : str , queue : Queue , event_type_name : Optional [ str ] = None , message_group_id : Optional [ str ] = None , message_deduplication_id : Optional [ str ] = None , ) -> None : raise NotImplementedError def acknowledge ( self , message : Message ) -> None : \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError def close_connection ( self ) -> None : \"\"\" Override this function if you want to use some finalizer code to shutdown your backend in a clean way \"\"\" pass def delete_queue ( self , queue : Queue ) -> None : \"\"\" Deletes the queue \"\"\" raise NotImplementedError def delete_topic ( self , topic : Topic ) -> None : \"\"\" Deletes the topic \"\"\" raise NotImplementedError acknowledge ( self , message ) Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future Source code in melange/backends/interfaces.py def acknowledge ( self , message : Message ) -> None : \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError close_connection ( self ) Override this function if you want to use some finalizer code to shutdown your backend in a clean way Source code in melange/backends/interfaces.py def close_connection ( self ) -> None : \"\"\" Override this function if you want to use some finalizer code to shutdown your backend in a clean way \"\"\" pass declare_queue ( self , queue_name , * topics_to_bind , * , dead_letter_queue_name = None , ** kwargs ) Creates a queue named queue_name if it does not exist. with default settings. Parameters: Name Type Description Default queue_name str the name of the queue to create required *topics_to_bind Topic if provided, creates all these topics and subscribes the created queue to them () dead_letter_queue_name Optional[str] if provided, create a dead letter queue attached to the created queue_name . None **kwargs Any {} Returns: Type Description Tuple[melange.backends.interfaces.Queue, Optional[melange.backends.interfaces.Queue]] A tuple with the created queue and the dead letter queue (if applies) Source code in melange/backends/interfaces.py def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : Optional [ str ] = None , ** kwargs : Any ) -> Tuple [ Queue , Optional [ Queue ]]: \"\"\" Creates a queue named `queue_name` if it does not exist. with default settings. Args: queue_name: the name of the queue to create *topics_to_bind: if provided, creates all these topics and subscribes the created queue to them dead_letter_queue_name: if provided, create a dead letter queue attached to the created `queue_name`. **kwargs: Returns: A tuple with the created queue and the dead letter queue (if applies) \"\"\" raise NotImplementedError declare_topic ( self , topic_name ) Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required Source code in melange/backends/interfaces.py def declare_topic ( self , topic_name : str ) -> Topic : \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required \"\"\" raise NotImplementedError delete_queue ( self , queue ) Deletes the queue Source code in melange/backends/interfaces.py def delete_queue ( self , queue : Queue ) -> None : \"\"\" Deletes the queue \"\"\" raise NotImplementedError delete_topic ( self , topic ) Deletes the topic Source code in melange/backends/interfaces.py def delete_topic ( self , topic : Topic ) -> None : \"\"\" Deletes the topic \"\"\" raise NotImplementedError get_queue ( self , queue_name ) Gets the queue with the name queue_name . Parameters: Name Type Description Default queue_name str the name of the queue to retrieve required Returns: Type Description Queue A Queue object that represents the created the queue Source code in melange/backends/interfaces.py def get_queue ( self , queue_name : str ) -> Queue : \"\"\" Gets the queue with the name `queue_name`. Args: queue_name: the name of the queue to retrieve Returns: A `Queue` object that represents the created the queue \"\"\" raise NotImplementedError publish ( self , content , topic , event_type_name , extra_attributes = None ) Publishes the content to the topic. The content must be a string (which is the json representation of an event) Source code in melange/backends/interfaces.py def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Optional [ Dict ] = None , ) -> None : \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError retrieve_messages ( self , queue , attempt_id = None ) Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process Source code in melange/backends/interfaces.py def retrieve_messages ( self , queue : Queue , attempt_id : Optional [ str ] = None ) -> List [ Message ]: \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError BackendManager This class should be used to initialize the type of messaging provider you want to use (Rabbit, AWS, etc) Source code in melange/backends/backend_manager.py class BackendManager ( metaclass = Singleton ): \"\"\" This class should be used to initialize the type of messaging provider you want to use (Rabbit, AWS, etc) \"\"\" def __init__ ( self ) -> None : self . _backend : Optional [ MessagingBackend ] = None def use_backend ( self , backend : MessagingBackend , ) -> None : if not isinstance ( backend , MessagingBackend ): raise Exception ( \"Invalid backend supplied\" ) self . _backend = backend def get_backend ( self ) -> MessagingBackend : if not self . _backend : raise Exception ( \"No backend is registered. Please call 'use_backend' prior to getting it\" ) return self . _backend SQSBackend ( MessagingBackend ) Source code in melange/backends/sqs/sqs_backend.py class SQSBackend ( MessagingBackend ): def __init__ ( self , ** kwargs ): super () . __init__ () self . max_number_of_messages = kwargs . get ( \"max_number_of_messages\" , 10 ) self . visibility_timeout = kwargs . get ( \"visibility_timeout\" , 100 ) self . wait_time_seconds = kwargs . get ( \"wait_time_seconds\" , 10 ) def declare_topic ( self , topic_name ) -> Topic : sns = boto3 . resource ( \"sns\" ) topic = sns . create_topic ( Name = topic_name ) return topic def get_queue ( self , queue_name ) -> Queue : sqs_res = boto3 . resource ( \"sqs\" ) return sqs_res . get_queue_by_name ( QueueName = queue_name ) def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : str = None , ** kwargs ) -> Tuple [ Queue , Queue ]: try : queue = self . get_queue ( queue_name ) except Exception : queue = self . _create_queue ( queue_name , content_based_deduplication = \"true\" ) if topics_to_bind : statements = [] for topic in topics_to_bind : statement = { \"Sid\" : \"Sid {} \" . format ( uuid . uuid4 ()), \"Effect\" : \"Allow\" , \"Principal\" : \"*\" , \"Resource\" : queue . attributes [ \"QueueArn\" ], \"Action\" : \"sqs:SendMessage\" , \"Condition\" : { \"ArnEquals\" : { \"aws:SourceArn\" : topic . arn }}, } statements . append ( statement ) subscription = topic . subscribe ( Protocol = \"sqs\" , Endpoint = queue . attributes [ \"QueueArn\" ], # , Attributes={\"RawMessageDelivery\": \"true\"} ) if kwargs . get ( \"filter_events\" ): filter_policy = { \"event_type\" : kwargs [ \"filter_events\" ]} else : filter_policy = {} subscription . set_attributes ( AttributeName = \"FilterPolicy\" , AttributeValue = json . dumps ( filter_policy ), ) policy = { \"Version\" : \"2012-10-17\" , \"Id\" : \"sqspolicy\" , \"Statement\" : statements , } queue . set_attributes ( Attributes = { \"Policy\" : json . dumps ( policy )}) dead_letter_queue = None if dead_letter_queue_name : try : dead_letter_queue = self . get_queue ( dead_letter_queue_name ) except Exception : dead_letter_queue = self . _create_queue ( dead_letter_queue_name , content_based_deduplication = \"true\" ) redrive_policy = { \"deadLetterTargetArn\" : dead_letter_queue . attributes [ \"QueueArn\" ], \"maxReceiveCount\" : \"4\" , } queue . set_attributes ( Attributes = { \"RedrivePolicy\" : json . dumps ( redrive_policy )} ) return queue , dead_letter_queue def _create_queue ( self , queue_name : str , ** kwargs ) -> Queue : sqs_res = boto3 . resource ( \"sqs\" ) fifo = queue_name . endswith ( \".fifo\" ) attributes = {} if fifo : attributes [ \"FifoQueue\" ] = \"true\" attributes [ \"ContentBasedDeduplication\" ] = ( \"true\" if kwargs . get ( \"content_based_deduplication\" ) else \"false\" ) queue = sqs_res . create_queue ( QueueName = queue_name , Attributes = attributes ) return queue def retrieve_messages ( self , queue : Queue , attempt_id = None ) -> List [ Message ]: kwargs = dict ( MaxNumberOfMessages = self . max_number_of_messages , VisibilityTimeout = self . visibility_timeout , WaitTimeSeconds = self . wait_time_seconds , MessageAttributeNames = [ \"All\" ], AttributeNames = [ \"All\" ], ) if attempt_id : kwargs [ \"ReceiveRequestAttemptId\" ] = attempt_id messages = queue . receive_messages ( ** kwargs ) # We need to differentiate here whether the message came from SNS or SQS return [ self . _construct_message ( message ) for message in messages ] def queue_publish ( self , content : str , queue , event_type_name : str = None , message_group_id : str = None , message_deduplication_id : str = None , ): kwargs = dict ( MessageBody = json . dumps ({ \"Message\" : content })) if event_type_name : kwargs [ \"MessageAttributes\" ] = { \"event_type\" : { \"DataType\" : \"String\" , \"StringValue\" : event_type_name } } if message_group_id : kwargs [ \"MessageGroupId\" ] = message_group_id if message_deduplication_id : kwargs [ \"MessageDeduplicationId\" ] = message_deduplication_id queue . send_message ( ** kwargs ) def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Dict = None , ): args = dict ( Message = content , MessageAttributes = { \"event_type\" : { \"DataType\" : \"String\" , \"StringValue\" : event_type_name } }, ) if extra_attributes : if \"subject\" in extra_attributes : args [ \"Subject\" ] = extra_attributes [ \"subject\" ] if \"message_attributes\" in extra_attributes : args [ \"MessageAttributes\" ] . update ( extra_attributes [ \"message_attributes\" ]) if \"message_structure\" in extra_attributes : args [ \"MessageStructure\" ] = extra_attributes [ \"message_structure\" ] response = topic . publish ( ** args ) if \"MessageId\" not in response : raise ConnectionError ( \"Could not send the event to the SNS TOPIC\" ) def acknowledge ( self , message : Message ) -> None : message . metadata . delete () def close_connection ( self ) -> None : pass def delete_queue ( self , queue : Queue ) -> None : queue . delete () def delete_topic ( self , topic : Topic ) -> None : topic . delete () def _construct_message ( self , message ) -> Message : body = message . body manifest = \"\" try : message_content = json . loads ( body ) if \"Message\" in message_content : content = message_content [ \"Message\" ] # Does the content have more attributes? If so, it is very likely that the message came from a non-raw # SNS redirection if \"MessageAttributes\" in message_content : manifest = ( message_content [ \"MessageAttributes\" ] . get ( \"event_type\" , {}) . get ( \"Value\" ) or \"\" ) else : content = message_content except JSONDecodeError : content = body manifest = ( manifest or message . message_attributes . get ( \"event_type\" , {}) . get ( \"StringValue\" ) or \"\" ) return Message ( message . message_id , content , message , manifest ) acknowledge ( self , message ) Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future Source code in melange/backends/sqs/sqs_backend.py def acknowledge ( self , message : Message ) -> None : message . metadata . delete () close_connection ( self ) Override this function if you want to use some finalizer code to shutdown your backend in a clean way Source code in melange/backends/sqs/sqs_backend.py def close_connection ( self ) -> None : pass declare_queue ( self , queue_name , * topics_to_bind , * , dead_letter_queue_name = None , ** kwargs ) Creates a queue named queue_name if it does not exist. with default settings. Parameters: Name Type Description Default queue_name str the name of the queue to create required *topics_to_bind Topic if provided, creates all these topics and subscribes the created queue to them () dead_letter_queue_name str if provided, create a dead letter queue attached to the created queue_name . None **kwargs {} Returns: Type Description Tuple[melange.backends.interfaces.Queue, melange.backends.interfaces.Queue] A tuple with the created queue and the dead letter queue (if applies) Source code in melange/backends/sqs/sqs_backend.py def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : str = None , ** kwargs ) -> Tuple [ Queue , Queue ]: try : queue = self . get_queue ( queue_name ) except Exception : queue = self . _create_queue ( queue_name , content_based_deduplication = \"true\" ) if topics_to_bind : statements = [] for topic in topics_to_bind : statement = { \"Sid\" : \"Sid {} \" . format ( uuid . uuid4 ()), \"Effect\" : \"Allow\" , \"Principal\" : \"*\" , \"Resource\" : queue . attributes [ \"QueueArn\" ], \"Action\" : \"sqs:SendMessage\" , \"Condition\" : { \"ArnEquals\" : { \"aws:SourceArn\" : topic . arn }}, } statements . append ( statement ) subscription = topic . subscribe ( Protocol = \"sqs\" , Endpoint = queue . attributes [ \"QueueArn\" ], # , Attributes={\"RawMessageDelivery\": \"true\"} ) if kwargs . get ( \"filter_events\" ): filter_policy = { \"event_type\" : kwargs [ \"filter_events\" ]} else : filter_policy = {} subscription . set_attributes ( AttributeName = \"FilterPolicy\" , AttributeValue = json . dumps ( filter_policy ), ) policy = { \"Version\" : \"2012-10-17\" , \"Id\" : \"sqspolicy\" , \"Statement\" : statements , } queue . set_attributes ( Attributes = { \"Policy\" : json . dumps ( policy )}) dead_letter_queue = None if dead_letter_queue_name : try : dead_letter_queue = self . get_queue ( dead_letter_queue_name ) except Exception : dead_letter_queue = self . _create_queue ( dead_letter_queue_name , content_based_deduplication = \"true\" ) redrive_policy = { \"deadLetterTargetArn\" : dead_letter_queue . attributes [ \"QueueArn\" ], \"maxReceiveCount\" : \"4\" , } queue . set_attributes ( Attributes = { \"RedrivePolicy\" : json . dumps ( redrive_policy )} ) return queue , dead_letter_queue declare_topic ( self , topic_name ) Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required Source code in melange/backends/sqs/sqs_backend.py def declare_topic ( self , topic_name ) -> Topic : sns = boto3 . resource ( \"sns\" ) topic = sns . create_topic ( Name = topic_name ) return topic delete_queue ( self , queue ) Deletes the queue Source code in melange/backends/sqs/sqs_backend.py def delete_queue ( self , queue : Queue ) -> None : queue . delete () delete_topic ( self , topic ) Deletes the topic Source code in melange/backends/sqs/sqs_backend.py def delete_topic ( self , topic : Topic ) -> None : topic . delete () get_queue ( self , queue_name ) Gets the queue with the name queue_name . Parameters: Name Type Description Default queue_name the name of the queue to retrieve required Returns: Type Description Queue A Queue object that represents the created the queue Source code in melange/backends/sqs/sqs_backend.py def get_queue ( self , queue_name ) -> Queue : sqs_res = boto3 . resource ( \"sqs\" ) return sqs_res . get_queue_by_name ( QueueName = queue_name ) publish ( self , content , topic , event_type_name , extra_attributes = None ) Publishes the content to the topic. The content must be a string (which is the json representation of an event) Source code in melange/backends/sqs/sqs_backend.py def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Dict = None , ): args = dict ( Message = content , MessageAttributes = { \"event_type\" : { \"DataType\" : \"String\" , \"StringValue\" : event_type_name } }, ) if extra_attributes : if \"subject\" in extra_attributes : args [ \"Subject\" ] = extra_attributes [ \"subject\" ] if \"message_attributes\" in extra_attributes : args [ \"MessageAttributes\" ] . update ( extra_attributes [ \"message_attributes\" ]) if \"message_structure\" in extra_attributes : args [ \"MessageStructure\" ] = extra_attributes [ \"message_structure\" ] response = topic . publish ( ** args ) if \"MessageId\" not in response : raise ConnectionError ( \"Could not send the event to the SNS TOPIC\" ) retrieve_messages ( self , queue , attempt_id = None ) Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process Source code in melange/backends/sqs/sqs_backend.py def retrieve_messages ( self , queue : Queue , attempt_id = None ) -> List [ Message ]: kwargs = dict ( MaxNumberOfMessages = self . max_number_of_messages , VisibilityTimeout = self . visibility_timeout , WaitTimeSeconds = self . wait_time_seconds , MessageAttributeNames = [ \"All\" ], AttributeNames = [ \"All\" ], ) if attempt_id : kwargs [ \"ReceiveRequestAttemptId\" ] = attempt_id messages = queue . receive_messages ( ** kwargs ) # We need to differentiate here whether the message came from SNS or SQS return [ self . _construct_message ( message ) for message in messages ]","title":"API reference"},{"location":"api-reference/#api-reference","text":"","title":"API reference"},{"location":"api-reference/#publishers","text":"","title":"Publishers"},{"location":"api-reference/#melange.publishers.TopicPublisher","text":"Some documentation here is in order Source code in melange/publishers.py class TopicPublisher : \"\"\" Some documentation here is in order \"\"\" def __init__ ( self , message_serializer : MessageSerializer , backend : Optional [ MessagingBackend ] = None , ) -> None : self . _backend = backend or BackendManager () . get_backend () self . message_serializer = message_serializer def publish ( self , topic_name : str , data : Any , ** extra_attributes : Any ) -> bool : topic = self . _backend . declare_topic ( topic_name ) content = self . message_serializer . serialize ( data ) manifest = self . message_serializer . manifest ( data ) self . _backend . publish ( content , topic , event_type_name = manifest , extra_attributes = extra_attributes , ) return True","title":"TopicPublisher"},{"location":"api-reference/#consumers","text":"","title":"Consumers"},{"location":"api-reference/#melange.consumers.SingleDispatchConsumer","text":"This class can consume events from a queue and pass them to a processor Source code in melange/consumers.py class SingleDispatchConsumer ( Consumer , SingleDispatch ): \"\"\" This class can consume events from a queue and pass them to a processor \"\"\" def process ( self , message : Any , ** kwargs : Any ) -> None : self . _process ( message ) @singledispatch def _process ( self , message : Any ) -> None : \"\"\"Event should be an instance of DomainEvent\"\"\" pass def listens_to ( self ) -> List [ str ]: accepted_events = filter ( lambda t : t is not object , self . _process . registry ) return lmap ( lambda ev_type : ev_type . __name__ , accepted_events ) def accepts ( self , manifest : Optional [ str ]) -> bool : \"\"\" Default implementation. You can override this if you want, for example, to accept any manifest and not only the type of classes you listen (useful to override in the face of subclasses) \"\"\" return not self . listens_to () or manifest in self . listens_to ()","title":"SingleDispatchConsumer"},{"location":"api-reference/#melange.consumers.SingleDispatchConsumer.accepts","text":"Default implementation. You can override this if you want, for example, to accept any manifest and not only the type of classes you listen (useful to override in the face of subclasses) Source code in melange/consumers.py def accepts ( self , manifest : Optional [ str ]) -> bool : \"\"\" Default implementation. You can override this if you want, for example, to accept any manifest and not only the type of classes you listen (useful to override in the face of subclasses) \"\"\" return not self . listens_to () or manifest in self . listens_to ()","title":"accepts()"},{"location":"api-reference/#messaging-backend-factory","text":"","title":"Messaging Backend Factory"},{"location":"api-reference/#serializers","text":"","title":"Serializers"},{"location":"api-reference/#melange.serializers.interfaces.MessageSerializer","text":"Base interface to inherit for all the serializers of the platform Source code in melange/serializers/interfaces.py class MessageSerializer ( Generic [ T ]): \"\"\" Base interface to inherit for all the serializers of the platform \"\"\" def manifest ( self , data : T ) -> str : return \"\" def deserialize ( self , data : str , manifest : Optional [ str ] = None ) -> T : pass def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass","title":"MessageSerializer"},{"location":"api-reference/#melange.serializers.interfaces.MessageSerializer.serialize","text":"Serializes and object to a string representation Source code in melange/serializers/interfaces.py def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass","title":"serialize()"},{"location":"api-reference/#melange.serializers.json.JsonSerializer","text":"Source code in melange/serializers/json.py class JsonSerializer ( MessageSerializer [ Dict ]): def manifest ( self , data : Dict ) -> str : return \"json\" def deserialize ( self , serialized_data : str , manifest : Optional [ str ] = None ) -> Dict : data = json . loads ( serialized_data ) return data def serialize ( self , data : Dict ) -> str : return json . dumps ( data )","title":"JsonSerializer"},{"location":"api-reference/#melange.serializers.json.JsonSerializer.serialize","text":"Serializes and object to a string representation Source code in melange/serializers/json.py def serialize ( self , data : Dict ) -> str : return json . dumps ( data )","title":"serialize()"},{"location":"api-reference/#melange.serializers.pickle.PickleSerializer","text":"Serializes DomainEvents with pickle Source code in melange/serializers/pickle.py class PickleSerializer ( MessageSerializer [ DomainEvent ]): \"\"\" Serializes DomainEvents with pickle \"\"\" def manifest ( self , data : DomainEvent ) -> str : return data . __class__ . __qualname__ def deserialize ( self , data : str , manifest : Optional [ str ] = None ) -> DomainEvent : return pickle . loads ( codecs . decode ( data . encode (), \"base64\" )) def serialize ( self , data : DomainEvent ) -> str : return codecs . encode ( pickle . dumps ( data ), \"base64\" ) . decode ()","title":"PickleSerializer"},{"location":"api-reference/#melange.serializers.pickle.PickleSerializer.serialize","text":"Serializes and object to a string representation Source code in melange/serializers/pickle.py def serialize ( self , data : DomainEvent ) -> str : return codecs . encode ( pickle . dumps ( data ), \"base64\" ) . decode ()","title":"serialize()"},{"location":"api-reference/#messaging-backends","text":"","title":"Messaging Backends"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend","text":"Source code in melange/backends/interfaces.py class MessagingBackend : def __init__ ( self ) -> None : self . _finalizer = weakref . finalize ( self , self . close_connection ) def declare_topic ( self , topic_name : str ) -> Topic : \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required \"\"\" raise NotImplementedError def get_queue ( self , queue_name : str ) -> Queue : \"\"\" Gets the queue with the name `queue_name`. Args: queue_name: the name of the queue to retrieve Returns: A `Queue` object that represents the created the queue \"\"\" raise NotImplementedError def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : Optional [ str ] = None , ** kwargs : Any ) -> Tuple [ Queue , Optional [ Queue ]]: \"\"\" Creates a queue named `queue_name` if it does not exist. with default settings. Args: queue_name: the name of the queue to create *topics_to_bind: if provided, creates all these topics and subscribes the created queue to them dead_letter_queue_name: if provided, create a dead letter queue attached to the created `queue_name`. **kwargs: Returns: A tuple with the created queue and the dead letter queue (if applies) \"\"\" raise NotImplementedError def retrieve_messages ( self , queue : Queue , attempt_id : Optional [ str ] = None ) -> List [ Message ]: \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Optional [ Dict ] = None , ) -> None : \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError def queue_publish ( self , content : str , queue : Queue , event_type_name : Optional [ str ] = None , message_group_id : Optional [ str ] = None , message_deduplication_id : Optional [ str ] = None , ) -> None : raise NotImplementedError def acknowledge ( self , message : Message ) -> None : \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError def close_connection ( self ) -> None : \"\"\" Override this function if you want to use some finalizer code to shutdown your backend in a clean way \"\"\" pass def delete_queue ( self , queue : Queue ) -> None : \"\"\" Deletes the queue \"\"\" raise NotImplementedError def delete_topic ( self , topic : Topic ) -> None : \"\"\" Deletes the topic \"\"\" raise NotImplementedError","title":"MessagingBackend"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend.acknowledge","text":"Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future Source code in melange/backends/interfaces.py def acknowledge ( self , message : Message ) -> None : \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError","title":"acknowledge()"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend.close_connection","text":"Override this function if you want to use some finalizer code to shutdown your backend in a clean way Source code in melange/backends/interfaces.py def close_connection ( self ) -> None : \"\"\" Override this function if you want to use some finalizer code to shutdown your backend in a clean way \"\"\" pass","title":"close_connection()"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend.declare_queue","text":"Creates a queue named queue_name if it does not exist. with default settings. Parameters: Name Type Description Default queue_name str the name of the queue to create required *topics_to_bind Topic if provided, creates all these topics and subscribes the created queue to them () dead_letter_queue_name Optional[str] if provided, create a dead letter queue attached to the created queue_name . None **kwargs Any {} Returns: Type Description Tuple[melange.backends.interfaces.Queue, Optional[melange.backends.interfaces.Queue]] A tuple with the created queue and the dead letter queue (if applies) Source code in melange/backends/interfaces.py def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : Optional [ str ] = None , ** kwargs : Any ) -> Tuple [ Queue , Optional [ Queue ]]: \"\"\" Creates a queue named `queue_name` if it does not exist. with default settings. Args: queue_name: the name of the queue to create *topics_to_bind: if provided, creates all these topics and subscribes the created queue to them dead_letter_queue_name: if provided, create a dead letter queue attached to the created `queue_name`. **kwargs: Returns: A tuple with the created queue and the dead letter queue (if applies) \"\"\" raise NotImplementedError","title":"declare_queue()"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend.declare_topic","text":"Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required Source code in melange/backends/interfaces.py def declare_topic ( self , topic_name : str ) -> Topic : \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required \"\"\" raise NotImplementedError","title":"declare_topic()"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend.delete_queue","text":"Deletes the queue Source code in melange/backends/interfaces.py def delete_queue ( self , queue : Queue ) -> None : \"\"\" Deletes the queue \"\"\" raise NotImplementedError","title":"delete_queue()"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend.delete_topic","text":"Deletes the topic Source code in melange/backends/interfaces.py def delete_topic ( self , topic : Topic ) -> None : \"\"\" Deletes the topic \"\"\" raise NotImplementedError","title":"delete_topic()"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend.get_queue","text":"Gets the queue with the name queue_name . Parameters: Name Type Description Default queue_name str the name of the queue to retrieve required Returns: Type Description Queue A Queue object that represents the created the queue Source code in melange/backends/interfaces.py def get_queue ( self , queue_name : str ) -> Queue : \"\"\" Gets the queue with the name `queue_name`. Args: queue_name: the name of the queue to retrieve Returns: A `Queue` object that represents the created the queue \"\"\" raise NotImplementedError","title":"get_queue()"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend.publish","text":"Publishes the content to the topic. The content must be a string (which is the json representation of an event) Source code in melange/backends/interfaces.py def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Optional [ Dict ] = None , ) -> None : \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError","title":"publish()"},{"location":"api-reference/#melange.backends.interfaces.MessagingBackend.retrieve_messages","text":"Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process Source code in melange/backends/interfaces.py def retrieve_messages ( self , queue : Queue , attempt_id : Optional [ str ] = None ) -> List [ Message ]: \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError","title":"retrieve_messages()"},{"location":"api-reference/#melange.backends.backend_manager.BackendManager","text":"This class should be used to initialize the type of messaging provider you want to use (Rabbit, AWS, etc) Source code in melange/backends/backend_manager.py class BackendManager ( metaclass = Singleton ): \"\"\" This class should be used to initialize the type of messaging provider you want to use (Rabbit, AWS, etc) \"\"\" def __init__ ( self ) -> None : self . _backend : Optional [ MessagingBackend ] = None def use_backend ( self , backend : MessagingBackend , ) -> None : if not isinstance ( backend , MessagingBackend ): raise Exception ( \"Invalid backend supplied\" ) self . _backend = backend def get_backend ( self ) -> MessagingBackend : if not self . _backend : raise Exception ( \"No backend is registered. Please call 'use_backend' prior to getting it\" ) return self . _backend","title":"BackendManager"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend","text":"Source code in melange/backends/sqs/sqs_backend.py class SQSBackend ( MessagingBackend ): def __init__ ( self , ** kwargs ): super () . __init__ () self . max_number_of_messages = kwargs . get ( \"max_number_of_messages\" , 10 ) self . visibility_timeout = kwargs . get ( \"visibility_timeout\" , 100 ) self . wait_time_seconds = kwargs . get ( \"wait_time_seconds\" , 10 ) def declare_topic ( self , topic_name ) -> Topic : sns = boto3 . resource ( \"sns\" ) topic = sns . create_topic ( Name = topic_name ) return topic def get_queue ( self , queue_name ) -> Queue : sqs_res = boto3 . resource ( \"sqs\" ) return sqs_res . get_queue_by_name ( QueueName = queue_name ) def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : str = None , ** kwargs ) -> Tuple [ Queue , Queue ]: try : queue = self . get_queue ( queue_name ) except Exception : queue = self . _create_queue ( queue_name , content_based_deduplication = \"true\" ) if topics_to_bind : statements = [] for topic in topics_to_bind : statement = { \"Sid\" : \"Sid {} \" . format ( uuid . uuid4 ()), \"Effect\" : \"Allow\" , \"Principal\" : \"*\" , \"Resource\" : queue . attributes [ \"QueueArn\" ], \"Action\" : \"sqs:SendMessage\" , \"Condition\" : { \"ArnEquals\" : { \"aws:SourceArn\" : topic . arn }}, } statements . append ( statement ) subscription = topic . subscribe ( Protocol = \"sqs\" , Endpoint = queue . attributes [ \"QueueArn\" ], # , Attributes={\"RawMessageDelivery\": \"true\"} ) if kwargs . get ( \"filter_events\" ): filter_policy = { \"event_type\" : kwargs [ \"filter_events\" ]} else : filter_policy = {} subscription . set_attributes ( AttributeName = \"FilterPolicy\" , AttributeValue = json . dumps ( filter_policy ), ) policy = { \"Version\" : \"2012-10-17\" , \"Id\" : \"sqspolicy\" , \"Statement\" : statements , } queue . set_attributes ( Attributes = { \"Policy\" : json . dumps ( policy )}) dead_letter_queue = None if dead_letter_queue_name : try : dead_letter_queue = self . get_queue ( dead_letter_queue_name ) except Exception : dead_letter_queue = self . _create_queue ( dead_letter_queue_name , content_based_deduplication = \"true\" ) redrive_policy = { \"deadLetterTargetArn\" : dead_letter_queue . attributes [ \"QueueArn\" ], \"maxReceiveCount\" : \"4\" , } queue . set_attributes ( Attributes = { \"RedrivePolicy\" : json . dumps ( redrive_policy )} ) return queue , dead_letter_queue def _create_queue ( self , queue_name : str , ** kwargs ) -> Queue : sqs_res = boto3 . resource ( \"sqs\" ) fifo = queue_name . endswith ( \".fifo\" ) attributes = {} if fifo : attributes [ \"FifoQueue\" ] = \"true\" attributes [ \"ContentBasedDeduplication\" ] = ( \"true\" if kwargs . get ( \"content_based_deduplication\" ) else \"false\" ) queue = sqs_res . create_queue ( QueueName = queue_name , Attributes = attributes ) return queue def retrieve_messages ( self , queue : Queue , attempt_id = None ) -> List [ Message ]: kwargs = dict ( MaxNumberOfMessages = self . max_number_of_messages , VisibilityTimeout = self . visibility_timeout , WaitTimeSeconds = self . wait_time_seconds , MessageAttributeNames = [ \"All\" ], AttributeNames = [ \"All\" ], ) if attempt_id : kwargs [ \"ReceiveRequestAttemptId\" ] = attempt_id messages = queue . receive_messages ( ** kwargs ) # We need to differentiate here whether the message came from SNS or SQS return [ self . _construct_message ( message ) for message in messages ] def queue_publish ( self , content : str , queue , event_type_name : str = None , message_group_id : str = None , message_deduplication_id : str = None , ): kwargs = dict ( MessageBody = json . dumps ({ \"Message\" : content })) if event_type_name : kwargs [ \"MessageAttributes\" ] = { \"event_type\" : { \"DataType\" : \"String\" , \"StringValue\" : event_type_name } } if message_group_id : kwargs [ \"MessageGroupId\" ] = message_group_id if message_deduplication_id : kwargs [ \"MessageDeduplicationId\" ] = message_deduplication_id queue . send_message ( ** kwargs ) def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Dict = None , ): args = dict ( Message = content , MessageAttributes = { \"event_type\" : { \"DataType\" : \"String\" , \"StringValue\" : event_type_name } }, ) if extra_attributes : if \"subject\" in extra_attributes : args [ \"Subject\" ] = extra_attributes [ \"subject\" ] if \"message_attributes\" in extra_attributes : args [ \"MessageAttributes\" ] . update ( extra_attributes [ \"message_attributes\" ]) if \"message_structure\" in extra_attributes : args [ \"MessageStructure\" ] = extra_attributes [ \"message_structure\" ] response = topic . publish ( ** args ) if \"MessageId\" not in response : raise ConnectionError ( \"Could not send the event to the SNS TOPIC\" ) def acknowledge ( self , message : Message ) -> None : message . metadata . delete () def close_connection ( self ) -> None : pass def delete_queue ( self , queue : Queue ) -> None : queue . delete () def delete_topic ( self , topic : Topic ) -> None : topic . delete () def _construct_message ( self , message ) -> Message : body = message . body manifest = \"\" try : message_content = json . loads ( body ) if \"Message\" in message_content : content = message_content [ \"Message\" ] # Does the content have more attributes? If so, it is very likely that the message came from a non-raw # SNS redirection if \"MessageAttributes\" in message_content : manifest = ( message_content [ \"MessageAttributes\" ] . get ( \"event_type\" , {}) . get ( \"Value\" ) or \"\" ) else : content = message_content except JSONDecodeError : content = body manifest = ( manifest or message . message_attributes . get ( \"event_type\" , {}) . get ( \"StringValue\" ) or \"\" ) return Message ( message . message_id , content , message , manifest )","title":"SQSBackend"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend.acknowledge","text":"Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future Source code in melange/backends/sqs/sqs_backend.py def acknowledge ( self , message : Message ) -> None : message . metadata . delete ()","title":"acknowledge()"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend.close_connection","text":"Override this function if you want to use some finalizer code to shutdown your backend in a clean way Source code in melange/backends/sqs/sqs_backend.py def close_connection ( self ) -> None : pass","title":"close_connection()"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend.declare_queue","text":"Creates a queue named queue_name if it does not exist. with default settings. Parameters: Name Type Description Default queue_name str the name of the queue to create required *topics_to_bind Topic if provided, creates all these topics and subscribes the created queue to them () dead_letter_queue_name str if provided, create a dead letter queue attached to the created queue_name . None **kwargs {} Returns: Type Description Tuple[melange.backends.interfaces.Queue, melange.backends.interfaces.Queue] A tuple with the created queue and the dead letter queue (if applies) Source code in melange/backends/sqs/sqs_backend.py def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : str = None , ** kwargs ) -> Tuple [ Queue , Queue ]: try : queue = self . get_queue ( queue_name ) except Exception : queue = self . _create_queue ( queue_name , content_based_deduplication = \"true\" ) if topics_to_bind : statements = [] for topic in topics_to_bind : statement = { \"Sid\" : \"Sid {} \" . format ( uuid . uuid4 ()), \"Effect\" : \"Allow\" , \"Principal\" : \"*\" , \"Resource\" : queue . attributes [ \"QueueArn\" ], \"Action\" : \"sqs:SendMessage\" , \"Condition\" : { \"ArnEquals\" : { \"aws:SourceArn\" : topic . arn }}, } statements . append ( statement ) subscription = topic . subscribe ( Protocol = \"sqs\" , Endpoint = queue . attributes [ \"QueueArn\" ], # , Attributes={\"RawMessageDelivery\": \"true\"} ) if kwargs . get ( \"filter_events\" ): filter_policy = { \"event_type\" : kwargs [ \"filter_events\" ]} else : filter_policy = {} subscription . set_attributes ( AttributeName = \"FilterPolicy\" , AttributeValue = json . dumps ( filter_policy ), ) policy = { \"Version\" : \"2012-10-17\" , \"Id\" : \"sqspolicy\" , \"Statement\" : statements , } queue . set_attributes ( Attributes = { \"Policy\" : json . dumps ( policy )}) dead_letter_queue = None if dead_letter_queue_name : try : dead_letter_queue = self . get_queue ( dead_letter_queue_name ) except Exception : dead_letter_queue = self . _create_queue ( dead_letter_queue_name , content_based_deduplication = \"true\" ) redrive_policy = { \"deadLetterTargetArn\" : dead_letter_queue . attributes [ \"QueueArn\" ], \"maxReceiveCount\" : \"4\" , } queue . set_attributes ( Attributes = { \"RedrivePolicy\" : json . dumps ( redrive_policy )} ) return queue , dead_letter_queue","title":"declare_queue()"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend.declare_topic","text":"Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required Source code in melange/backends/sqs/sqs_backend.py def declare_topic ( self , topic_name ) -> Topic : sns = boto3 . resource ( \"sns\" ) topic = sns . create_topic ( Name = topic_name ) return topic","title":"declare_topic()"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend.delete_queue","text":"Deletes the queue Source code in melange/backends/sqs/sqs_backend.py def delete_queue ( self , queue : Queue ) -> None : queue . delete ()","title":"delete_queue()"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend.delete_topic","text":"Deletes the topic Source code in melange/backends/sqs/sqs_backend.py def delete_topic ( self , topic : Topic ) -> None : topic . delete ()","title":"delete_topic()"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend.get_queue","text":"Gets the queue with the name queue_name . Parameters: Name Type Description Default queue_name the name of the queue to retrieve required Returns: Type Description Queue A Queue object that represents the created the queue Source code in melange/backends/sqs/sqs_backend.py def get_queue ( self , queue_name ) -> Queue : sqs_res = boto3 . resource ( \"sqs\" ) return sqs_res . get_queue_by_name ( QueueName = queue_name )","title":"get_queue()"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend.publish","text":"Publishes the content to the topic. The content must be a string (which is the json representation of an event) Source code in melange/backends/sqs/sqs_backend.py def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Dict = None , ): args = dict ( Message = content , MessageAttributes = { \"event_type\" : { \"DataType\" : \"String\" , \"StringValue\" : event_type_name } }, ) if extra_attributes : if \"subject\" in extra_attributes : args [ \"Subject\" ] = extra_attributes [ \"subject\" ] if \"message_attributes\" in extra_attributes : args [ \"MessageAttributes\" ] . update ( extra_attributes [ \"message_attributes\" ]) if \"message_structure\" in extra_attributes : args [ \"MessageStructure\" ] = extra_attributes [ \"message_structure\" ] response = topic . publish ( ** args ) if \"MessageId\" not in response : raise ConnectionError ( \"Could not send the event to the SNS TOPIC\" )","title":"publish()"},{"location":"api-reference/#melange.backends.sqs.sqs_backend.SQSBackend.retrieve_messages","text":"Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process Source code in melange/backends/sqs/sqs_backend.py def retrieve_messages ( self , queue : Queue , attempt_id = None ) -> List [ Message ]: kwargs = dict ( MaxNumberOfMessages = self . max_number_of_messages , VisibilityTimeout = self . visibility_timeout , WaitTimeSeconds = self . wait_time_seconds , MessageAttributeNames = [ \"All\" ], AttributeNames = [ \"All\" ], ) if attempt_id : kwargs [ \"ReceiveRequestAttemptId\" ] = attempt_id messages = queue . receive_messages ( ** kwargs ) # We need to differentiate here whether the message came from SNS or SQS return [ self . _construct_message ( message ) for message in messages ]","title":"retrieve_messages()"},{"location":"behind-scenes/","text":"Behind the scenes How are messages serialized Messages, when serialized, they have the shape of a string. Some serializing formats might not require anything more that the message itself (like pickle). The message itself contains headers of some kind that tells deserializers how they have to deserialize that message (assuming you already know you always have to use that specific serializer). Other formats (like protobuf) require some kind of specification that tells the consumers how the message needs to be deserialized. This is why manifests exist and are necessary. A manifest tells the aplicacion which shape (manifestation) an array of bytes or a string had. This way we can appropriately choose the serializer that is able to properly deserialize the message. Imagine we want to serialize an object with a serializer that performs encryption as well: @dataclass class ProductCreated : id : int name : str event = ProductCreated ( 1 , \"Banana\" ) serialzer = MyCryptographicSerializer () serialized_event = serializer . serialize ( event ) # Let's say `serialized_event` has this content: # a&/(67567ulmtensr/((&/...29747JJJ If we just sent that string to an outsider, how does it know that is a ProductCreated which has been serialized with a special serializer? However, with the aid of the manifest, we can give some clue to the deserializer on how that message was serialized: @dataclass class ProductCreated : id : int name : str event = ProductCreated ( 1 , \"Banana\" ) serialzer = MyCryptographicSerializer () serialized_event = serializer . serialize ( event ) # Let's say `serialized_event` has this content: # a&/(67567ulmtensr/((&/...29747JJJ manifest = serializer . manifest ( event ) # manifest could be something like `mycryptoserializer:sha1:ProductCreated` That way we tell the consumer who has to deserialize the message that the message was serialized with the MyCryptographicSerializer , with a SHA1 algorithm, and that it is a ProductCreated event. The publishers, when sending the message, they send the manifest as well as the serialized message to provide the consumers with this valuable information. The manifest could be sent through the means of metadata (if your messaging infrastructure supports it) or through any other means that could be retrieved by the consumer.","title":"Behind the scenes"},{"location":"behind-scenes/#behind-the-scenes","text":"","title":"Behind the scenes"},{"location":"behind-scenes/#how-are-messages-serialized","text":"Messages, when serialized, they have the shape of a string. Some serializing formats might not require anything more that the message itself (like pickle). The message itself contains headers of some kind that tells deserializers how they have to deserialize that message (assuming you already know you always have to use that specific serializer). Other formats (like protobuf) require some kind of specification that tells the consumers how the message needs to be deserialized. This is why manifests exist and are necessary. A manifest tells the aplicacion which shape (manifestation) an array of bytes or a string had. This way we can appropriately choose the serializer that is able to properly deserialize the message. Imagine we want to serialize an object with a serializer that performs encryption as well: @dataclass class ProductCreated : id : int name : str event = ProductCreated ( 1 , \"Banana\" ) serialzer = MyCryptographicSerializer () serialized_event = serializer . serialize ( event ) # Let's say `serialized_event` has this content: # a&/(67567ulmtensr/((&/...29747JJJ If we just sent that string to an outsider, how does it know that is a ProductCreated which has been serialized with a special serializer? However, with the aid of the manifest, we can give some clue to the deserializer on how that message was serialized: @dataclass class ProductCreated : id : int name : str event = ProductCreated ( 1 , \"Banana\" ) serialzer = MyCryptographicSerializer () serialized_event = serializer . serialize ( event ) # Let's say `serialized_event` has this content: # a&/(67567ulmtensr/((&/...29747JJJ manifest = serializer . manifest ( event ) # manifest could be something like `mycryptoserializer:sha1:ProductCreated` That way we tell the consumer who has to deserialize the message that the message was serialized with the MyCryptographicSerializer , with a SHA1 algorithm, and that it is a ProductCreated event. The publishers, when sending the message, they send the manifest as well as the serialized message to provide the consumers with this valuable information. The manifest could be sent through the means of metadata (if your messaging infrastructure supports it) or through any other means that could be retrieved by the consumer.","title":"How are messages serialized"},{"location":"factory/","text":"Factory Although you could set up your own topics and queues in your infrastructure (e.g. by using terraform) you can rely on Personally I have no strong feelings over defining your queues and topics through an infrastructure-as-code framework or letting the application create it's own queues and topics (as long as it has the appropriate permissions to do so). In any case, Melange offers a factory to create queues and topics for you with the MessagingBackendFactory . The factory initialization methods are idempotent. If a queue or a topic already exist, they will keep the same queue or topic, but override any settings or customizations that you might have manually set in your PaaS platform. Creating a queue Let's say you'd wish to create an Amazon SQS queue to listen to the events for a payment service. You could invoke the factory as follows: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" ) This will create a FIFO queue payment-updates in your AWS account (remember to appropriately set the AWS variables since the SQS backend uses boto behind the scenes). You could also define a dead letter queue for messages that could not be delivered successfully: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" , dead_letter_queue_name = \"payment-updates.fifo\" ) Creating a topic Topics apply the fan-out pattern to send the message to anyone who is subscribed to them. They are useful to decouple your consumers from your application so that they don't need to know who they are sending their messages to. With the factory you could create a topic like this: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_topic ( \"my-topic\" ) For the SQSBackend this will create an SNS topic. Creating a queue and subscribing it to several topics You could create a queue and immediately subscribe it to a number of topics: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" , \"my-topic-1\" , \"my-topic-2\" , \"my-topic-3\" , dead_letter_queue_name = \"payment-updates.fifo\" ) This will create the topics my-topic-1 , my-topic-2 and my-topic-3 , then create the payment-updates.fifo queue, and subscribe it to the aforementioned topics. It will create the dead letter queue too.","title":"Factory"},{"location":"factory/#factory","text":"Although you could set up your own topics and queues in your infrastructure (e.g. by using terraform) you can rely on Personally I have no strong feelings over defining your queues and topics through an infrastructure-as-code framework or letting the application create it's own queues and topics (as long as it has the appropriate permissions to do so). In any case, Melange offers a factory to create queues and topics for you with the MessagingBackendFactory . The factory initialization methods are idempotent. If a queue or a topic already exist, they will keep the same queue or topic, but override any settings or customizations that you might have manually set in your PaaS platform.","title":"Factory"},{"location":"factory/#creating-a-queue","text":"Let's say you'd wish to create an Amazon SQS queue to listen to the events for a payment service. You could invoke the factory as follows: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" ) This will create a FIFO queue payment-updates in your AWS account (remember to appropriately set the AWS variables since the SQS backend uses boto behind the scenes). You could also define a dead letter queue for messages that could not be delivered successfully: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" , dead_letter_queue_name = \"payment-updates.fifo\" )","title":"Creating a queue"},{"location":"factory/#creating-a-topic","text":"Topics apply the fan-out pattern to send the message to anyone who is subscribed to them. They are useful to decouple your consumers from your application so that they don't need to know who they are sending their messages to. With the factory you could create a topic like this: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_topic ( \"my-topic\" ) For the SQSBackend this will create an SNS topic.","title":"Creating a topic"},{"location":"factory/#creating-a-queue-and-subscribing-it-to-several-topics","text":"You could create a queue and immediately subscribe it to a number of topics: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" , \"my-topic-1\" , \"my-topic-2\" , \"my-topic-3\" , dead_letter_queue_name = \"payment-updates.fifo\" ) This will create the topics my-topic-1 , my-topic-2 and my-topic-3 , then create the payment-updates.fifo queue, and subscribe it to the aforementioned topics. It will create the dead letter queue too.","title":"Creating a queue and subscribing it to several topics"},{"location":"principles/","text":"Ideas and principles TODO: Complete this section with accurate information Melange builds upon the concepts of Domain Driven Design. If want to have a clean event-driven architecture with Domain Events, and its idea has been grabbed from Vaughn Vernon and his must-read book Implementing Domain-Driven Design (look at part 3 of these series if you want a quick look, or read this excellent article from Udi Dahan, founder of NServiceBus ). If you wanna learn more about how to do clean architectures and domain well isolated from your technology stack I advise, again, to read Implementing Domain-Driven Design from Vaughn Vernon and Clean Architecture from Uncle Bob","title":"Principles"},{"location":"principles/#ideas-and-principles","text":"TODO: Complete this section with accurate information Melange builds upon the concepts of Domain Driven Design. If want to have a clean event-driven architecture with Domain Events, and its idea has been grabbed from Vaughn Vernon and his must-read book Implementing Domain-Driven Design (look at part 3 of these series if you want a quick look, or read this excellent article from Udi Dahan, founder of NServiceBus ). If you wanna learn more about how to do clean architectures and domain well isolated from your technology stack I advise, again, to read Implementing Domain-Driven Design from Vaughn Vernon and Clean Architecture from Uncle Bob","title":"Ideas and principles"},{"location":"roadmap/","text":"Roadmap Multiple serializers Right now, you can only supply one serializer to a publisher or a consumer, and the same serializer will always be used for all the messages published and received. This could be extended to support multiple serializers, and then let the library choose the appropriate library to use depending on the type of the message or the attached manifest. That way you could even implement serializer versioning (e.g. have different versions of the same serializer) The akka framework implements a similar concept . Kombu integration Maybe The Messaging Backends could be entirely replaced with Kombu, since kombu already offers an abstraction layer over several messaging brokers. Undergo some kind of proof of concept to see if such a thing is possible and how.","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"","title":"Roadmap"},{"location":"roadmap/#multiple-serializers","text":"Right now, you can only supply one serializer to a publisher or a consumer, and the same serializer will always be used for all the messages published and received. This could be extended to support multiple serializers, and then let the library choose the appropriate library to use depending on the type of the message or the attached manifest. That way you could even implement serializer versioning (e.g. have different versions of the same serializer) The akka framework implements a similar concept .","title":"Multiple serializers"},{"location":"roadmap/#kombu-integration","text":"Maybe The Messaging Backends could be entirely replaced with Kombu, since kombu already offers an abstraction layer over several messaging brokers. Undergo some kind of proof of concept to see if such a thing is possible and how.","title":"Kombu integration"},{"location":"testing/","text":"Testing Any developer worth its salt does some kind of testing over the code they develop. However, testing software that spans several processes/threads (like when you do pub/sub over a queue/topic) can be a daunting task. Melange offers several utilities to help you test your publishers and consumers (or just making everything synchronous inside the context of the test for the sake of simplicity). Here some examples are presented on how you could potentially use the library in your tests. Asynchronous testing with threads In a regular test, you would have to do the following steps if you would like to test a Consumer, or see if your whole network of consumers reacts appropriately to the messages your application sends (when doing, for example, end-to-end tests): Make sure to create (or ensure that they exist at least) the queues and topics where the message exchange happens. Start the consumer loop in a separate thread, and make sure the thread is stopped upon termination of the test. Call your code that invokes the publishing methods, and have probes in place that poll the environment to check whether the consumers have done their work or not before doing any kind of assertion that requires the work of some consumer to be done. Bonus: After the test is finished, take down the queue/topic to keep the environment clean. Full Example: import os import threading from dataclasses import dataclass from typing import Optional , Dict import polling from hamcrest import * from melange.backends.factory import MessagingBackendFactory from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.consumers import Consumer , SimpleConsumerHandler from melange.examples.doc_examples.probe import Probe from melange.publishers import QueuePublisher from melange.serializers.pickle import PickleSerializer class StateProbe ( Probe ): def __init__ ( self , state : \"State\" ) -> None : self . state = state def sample ( self ) -> None : pass def can_be_measured ( self ) -> bool : self . sample () return self . state . value_set is not None def wait ( self ) -> None : try : polling . poll ( self . can_be_measured , 1 , timeout = 60 ) except polling . TimeoutException as e : raise Exception ( \"Timeout!\" ) from e @dataclass class State : value_set : Optional [ int ] = None def test_async_consumer ( request ): serializer = PickleSerializer () # We'll use the ElasticMQ as backend since it works like a real SQS queue backend = ElasticMQBackend ( host = os . environ . get ( \"SQSHOST\" ), port = os . environ . get ( \"SQSPORT\" ) ) queue_name = \"testqueue\" # Initialize the queue queue = MessagingBackendFactory ( backend ) . init_queue ( queue_name ) # Delete the queue upon finishing the execution of the test def teardown (): backend . delete_queue ( queue ) request . addfinalizer ( teardown ) # Create a consumer that, upon receiving a message, will set # the variable \"value set\" to later assert that this value # has, indeed, been set by the consumer that is running on another thread state = State () def set_state ( message : Dict ) -> None : state . value_set = message [ \"value\" ] consumer = Consumer ( on_message = set_state ) handler = SimpleConsumerHandler ( consumer , serializer , backend = backend ) # Start the consumer loop thread to run the consumer loop in the background threading . Thread ( target = lambda : handler . consume_loop ( queue_name ), daemon = True ) . start () # Publish a message and... publisher = QueuePublisher ( serializer , backend ) publisher . publish ( queue_name , { \"value\" : 1 }) # ...wait until the value is set probe = StateProbe ( state ) probe . wait () assert_that ( state . value_set , is_ ( 1 )) This kind of test has the advantage of being very explicit in the sense that it expresses, through the probe, that this test has some asynchronous processing in the background, and waits for it. It's quite realistic as well, pub/sub is asynchronous in its nature and we work with it in this test. However the arrangement is complex. It's a trade-off between completeness and complexity that you have to embrace if you want to follow this route. TIP: Try to abstract away all this arrangement code from the main body of the test to keep it clean and clear, avoiding pollution. Testing frameworks have different techniques to abstract away arrangements (like pytest fixtures). Synchronous testing with the InMemoryMessagingBackend Another option is to use the bundled InMemoryMessagingBackend when instantiating your publishers and consumers. This will make the entirety of the test synchronous in respect to the message passing. from melange.backends.testing import InMemoryMessagingBackend , link_synchronously from melange.consumers import Consumer from melange.publishers import QueuePublisher from melange.serializers.pickle import PickleSerializer def test_inmemory_messaging_backend (): consumer_1 = Consumer ( lambda message : print ( f \"Hello { message [ 'message' ] } !\" )) consumer_2 = Consumer ( lambda message : print ( f \"Hello { message [ 'message' ] } 2!\" )) serializer = PickleSerializer () backend = InMemoryMessagingBackend () link_synchronously ( \"somequeue\" , [ consumer_1 , consumer_2 ], serializer , backend ) publisher = QueuePublisher ( PickleSerializer (), backend = backend ) publisher . publish ( \"somequeue\" , { \"message\" : \"Mary\" }) What the InMemoryMessagingBackend does, upon publish, is to store the serialized message in memory and forward it to the internal consumer dispatcher, so that the consumers can synchronously receive and process the message. The link_synchronously function is a helper which glues everything together. All the messages sent to the queue or topic with that name will be dispatched to those consumers (if the consumers accept that message).","title":"Testing"},{"location":"testing/#testing","text":"Any developer worth its salt does some kind of testing over the code they develop. However, testing software that spans several processes/threads (like when you do pub/sub over a queue/topic) can be a daunting task. Melange offers several utilities to help you test your publishers and consumers (or just making everything synchronous inside the context of the test for the sake of simplicity). Here some examples are presented on how you could potentially use the library in your tests.","title":"Testing"},{"location":"testing/#asynchronous-testing-with-threads","text":"In a regular test, you would have to do the following steps if you would like to test a Consumer, or see if your whole network of consumers reacts appropriately to the messages your application sends (when doing, for example, end-to-end tests): Make sure to create (or ensure that they exist at least) the queues and topics where the message exchange happens. Start the consumer loop in a separate thread, and make sure the thread is stopped upon termination of the test. Call your code that invokes the publishing methods, and have probes in place that poll the environment to check whether the consumers have done their work or not before doing any kind of assertion that requires the work of some consumer to be done. Bonus: After the test is finished, take down the queue/topic to keep the environment clean. Full Example: import os import threading from dataclasses import dataclass from typing import Optional , Dict import polling from hamcrest import * from melange.backends.factory import MessagingBackendFactory from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.consumers import Consumer , SimpleConsumerHandler from melange.examples.doc_examples.probe import Probe from melange.publishers import QueuePublisher from melange.serializers.pickle import PickleSerializer class StateProbe ( Probe ): def __init__ ( self , state : \"State\" ) -> None : self . state = state def sample ( self ) -> None : pass def can_be_measured ( self ) -> bool : self . sample () return self . state . value_set is not None def wait ( self ) -> None : try : polling . poll ( self . can_be_measured , 1 , timeout = 60 ) except polling . TimeoutException as e : raise Exception ( \"Timeout!\" ) from e @dataclass class State : value_set : Optional [ int ] = None def test_async_consumer ( request ): serializer = PickleSerializer () # We'll use the ElasticMQ as backend since it works like a real SQS queue backend = ElasticMQBackend ( host = os . environ . get ( \"SQSHOST\" ), port = os . environ . get ( \"SQSPORT\" ) ) queue_name = \"testqueue\" # Initialize the queue queue = MessagingBackendFactory ( backend ) . init_queue ( queue_name ) # Delete the queue upon finishing the execution of the test def teardown (): backend . delete_queue ( queue ) request . addfinalizer ( teardown ) # Create a consumer that, upon receiving a message, will set # the variable \"value set\" to later assert that this value # has, indeed, been set by the consumer that is running on another thread state = State () def set_state ( message : Dict ) -> None : state . value_set = message [ \"value\" ] consumer = Consumer ( on_message = set_state ) handler = SimpleConsumerHandler ( consumer , serializer , backend = backend ) # Start the consumer loop thread to run the consumer loop in the background threading . Thread ( target = lambda : handler . consume_loop ( queue_name ), daemon = True ) . start () # Publish a message and... publisher = QueuePublisher ( serializer , backend ) publisher . publish ( queue_name , { \"value\" : 1 }) # ...wait until the value is set probe = StateProbe ( state ) probe . wait () assert_that ( state . value_set , is_ ( 1 )) This kind of test has the advantage of being very explicit in the sense that it expresses, through the probe, that this test has some asynchronous processing in the background, and waits for it. It's quite realistic as well, pub/sub is asynchronous in its nature and we work with it in this test. However the arrangement is complex. It's a trade-off between completeness and complexity that you have to embrace if you want to follow this route. TIP: Try to abstract away all this arrangement code from the main body of the test to keep it clean and clear, avoiding pollution. Testing frameworks have different techniques to abstract away arrangements (like pytest fixtures).","title":"Asynchronous testing with threads"},{"location":"testing/#synchronous-testing-with-the-inmemorymessagingbackend","text":"Another option is to use the bundled InMemoryMessagingBackend when instantiating your publishers and consumers. This will make the entirety of the test synchronous in respect to the message passing. from melange.backends.testing import InMemoryMessagingBackend , link_synchronously from melange.consumers import Consumer from melange.publishers import QueuePublisher from melange.serializers.pickle import PickleSerializer def test_inmemory_messaging_backend (): consumer_1 = Consumer ( lambda message : print ( f \"Hello { message [ 'message' ] } !\" )) consumer_2 = Consumer ( lambda message : print ( f \"Hello { message [ 'message' ] } 2!\" )) serializer = PickleSerializer () backend = InMemoryMessagingBackend () link_synchronously ( \"somequeue\" , [ consumer_1 , consumer_2 ], serializer , backend ) publisher = QueuePublisher ( PickleSerializer (), backend = backend ) publisher . publish ( \"somequeue\" , { \"message\" : \"Mary\" }) What the InMemoryMessagingBackend does, upon publish, is to store the serialized message in memory and forward it to the internal consumer dispatcher, so that the consumers can synchronously receive and process the message. The link_synchronously function is a helper which glues everything together. All the messages sent to the queue or topic with that name will be dispatched to those consumers (if the consumers accept that message).","title":"Synchronous testing with the InMemoryMessagingBackend"},{"location":"components/consumers/","text":"Consumers Consumers are the counterpart of the publishers. They receive and consume the messages from a queue, and dispatch the message to a method that handles that message. To implement a consumer with Melange one of the approaches is to subclass the Consumer class and implement the process method. Example","title":"Consumers"},{"location":"components/consumers/#consumers","text":"Consumers are the counterpart of the publishers. They receive and consume the messages from a queue, and dispatch the message to a method that handles that message. To implement a consumer with Melange one of the approaches is to subclass the Consumer class and implement the process method. Example","title":"Consumers"},{"location":"components/messaging-backends/","text":"Messaging backends A messaging backend is a wrapper over your message broker. It exposes several methods that abstract the broker functionality, making it simpler to work with. Out of the box Melange provides you with three messaging backends: The SQSBackend , the RabbitMQBackend and the ElasticMQBackend . Writing your own Messaging Backend Subclass the MessagingBackend interface and implement all the methods of that class. Here is the documentation of the interface class and all its methods: MessagingBackend Source code in melange/backends/interfaces.py class MessagingBackend : def __init__ ( self ) -> None : self . _finalizer = weakref . finalize ( self , self . close_connection ) def declare_topic ( self , topic_name : str ) -> Topic : \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required \"\"\" raise NotImplementedError def get_queue ( self , queue_name : str ) -> Queue : \"\"\" Gets the queue with the name `queue_name`. Args: queue_name: the name of the queue to retrieve Returns: A `Queue` object that represents the created the queue \"\"\" raise NotImplementedError def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : Optional [ str ] = None , ** kwargs : Any ) -> Tuple [ Queue , Optional [ Queue ]]: \"\"\" Creates a queue named `queue_name` if it does not exist. with default settings. Args: queue_name: the name of the queue to create *topics_to_bind: if provided, creates all these topics and subscribes the created queue to them dead_letter_queue_name: if provided, create a dead letter queue attached to the created `queue_name`. **kwargs: Returns: A tuple with the created queue and the dead letter queue (if applies) \"\"\" raise NotImplementedError def retrieve_messages ( self , queue : Queue , attempt_id : Optional [ str ] = None ) -> List [ Message ]: \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Optional [ Dict ] = None , ) -> None : \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError def queue_publish ( self , content : str , queue : Queue , event_type_name : Optional [ str ] = None , message_group_id : Optional [ str ] = None , message_deduplication_id : Optional [ str ] = None , ) -> None : raise NotImplementedError def acknowledge ( self , message : Message ) -> None : \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError def close_connection ( self ) -> None : \"\"\" Override this function if you want to use some finalizer code to shutdown your backend in a clean way \"\"\" pass def delete_queue ( self , queue : Queue ) -> None : \"\"\" Deletes the queue \"\"\" raise NotImplementedError def delete_topic ( self , topic : Topic ) -> None : \"\"\" Deletes the topic \"\"\" raise NotImplementedError acknowledge ( self , message ) Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future Source code in melange/backends/interfaces.py def acknowledge ( self , message : Message ) -> None : \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError close_connection ( self ) Override this function if you want to use some finalizer code to shutdown your backend in a clean way Source code in melange/backends/interfaces.py def close_connection ( self ) -> None : \"\"\" Override this function if you want to use some finalizer code to shutdown your backend in a clean way \"\"\" pass declare_queue ( self , queue_name , * topics_to_bind , * , dead_letter_queue_name = None , ** kwargs ) Creates a queue named queue_name if it does not exist. with default settings. Parameters: Name Type Description Default queue_name str the name of the queue to create required *topics_to_bind Topic if provided, creates all these topics and subscribes the created queue to them () dead_letter_queue_name Optional[str] if provided, create a dead letter queue attached to the created queue_name . None **kwargs Any {} Returns: Type Description Tuple[melange.backends.interfaces.Queue, Optional[melange.backends.interfaces.Queue]] A tuple with the created queue and the dead letter queue (if applies) Source code in melange/backends/interfaces.py def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : Optional [ str ] = None , ** kwargs : Any ) -> Tuple [ Queue , Optional [ Queue ]]: \"\"\" Creates a queue named `queue_name` if it does not exist. with default settings. Args: queue_name: the name of the queue to create *topics_to_bind: if provided, creates all these topics and subscribes the created queue to them dead_letter_queue_name: if provided, create a dead letter queue attached to the created `queue_name`. **kwargs: Returns: A tuple with the created queue and the dead letter queue (if applies) \"\"\" raise NotImplementedError declare_topic ( self , topic_name ) Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required Source code in melange/backends/interfaces.py def declare_topic ( self , topic_name : str ) -> Topic : \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required \"\"\" raise NotImplementedError delete_queue ( self , queue ) Deletes the queue Source code in melange/backends/interfaces.py def delete_queue ( self , queue : Queue ) -> None : \"\"\" Deletes the queue \"\"\" raise NotImplementedError delete_topic ( self , topic ) Deletes the topic Source code in melange/backends/interfaces.py def delete_topic ( self , topic : Topic ) -> None : \"\"\" Deletes the topic \"\"\" raise NotImplementedError get_queue ( self , queue_name ) Gets the queue with the name queue_name . Parameters: Name Type Description Default queue_name str the name of the queue to retrieve required Returns: Type Description Queue A Queue object that represents the created the queue Source code in melange/backends/interfaces.py def get_queue ( self , queue_name : str ) -> Queue : \"\"\" Gets the queue with the name `queue_name`. Args: queue_name: the name of the queue to retrieve Returns: A `Queue` object that represents the created the queue \"\"\" raise NotImplementedError publish ( self , content , topic , event_type_name , extra_attributes = None ) Publishes the content to the topic. The content must be a string (which is the json representation of an event) Source code in melange/backends/interfaces.py def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Optional [ Dict ] = None , ) -> None : \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError retrieve_messages ( self , queue , attempt_id = None ) Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process Source code in melange/backends/interfaces.py def retrieve_messages ( self , queue : Queue , attempt_id : Optional [ str ] = None ) -> List [ Message ]: \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError","title":"Messaging Backends"},{"location":"components/messaging-backends/#messaging-backends","text":"A messaging backend is a wrapper over your message broker. It exposes several methods that abstract the broker functionality, making it simpler to work with. Out of the box Melange provides you with three messaging backends: The SQSBackend , the RabbitMQBackend and the ElasticMQBackend .","title":"Messaging backends"},{"location":"components/messaging-backends/#writing-your-own-messaging-backend","text":"Subclass the MessagingBackend interface and implement all the methods of that class. Here is the documentation of the interface class and all its methods:","title":"Writing your own Messaging Backend"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend","text":"Source code in melange/backends/interfaces.py class MessagingBackend : def __init__ ( self ) -> None : self . _finalizer = weakref . finalize ( self , self . close_connection ) def declare_topic ( self , topic_name : str ) -> Topic : \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required \"\"\" raise NotImplementedError def get_queue ( self , queue_name : str ) -> Queue : \"\"\" Gets the queue with the name `queue_name`. Args: queue_name: the name of the queue to retrieve Returns: A `Queue` object that represents the created the queue \"\"\" raise NotImplementedError def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : Optional [ str ] = None , ** kwargs : Any ) -> Tuple [ Queue , Optional [ Queue ]]: \"\"\" Creates a queue named `queue_name` if it does not exist. with default settings. Args: queue_name: the name of the queue to create *topics_to_bind: if provided, creates all these topics and subscribes the created queue to them dead_letter_queue_name: if provided, create a dead letter queue attached to the created `queue_name`. **kwargs: Returns: A tuple with the created queue and the dead letter queue (if applies) \"\"\" raise NotImplementedError def retrieve_messages ( self , queue : Queue , attempt_id : Optional [ str ] = None ) -> List [ Message ]: \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Optional [ Dict ] = None , ) -> None : \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError def queue_publish ( self , content : str , queue : Queue , event_type_name : Optional [ str ] = None , message_group_id : Optional [ str ] = None , message_deduplication_id : Optional [ str ] = None , ) -> None : raise NotImplementedError def acknowledge ( self , message : Message ) -> None : \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError def close_connection ( self ) -> None : \"\"\" Override this function if you want to use some finalizer code to shutdown your backend in a clean way \"\"\" pass def delete_queue ( self , queue : Queue ) -> None : \"\"\" Deletes the queue \"\"\" raise NotImplementedError def delete_topic ( self , topic : Topic ) -> None : \"\"\" Deletes the topic \"\"\" raise NotImplementedError","title":"MessagingBackend"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend.acknowledge","text":"Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future Source code in melange/backends/interfaces.py def acknowledge ( self , message : Message ) -> None : \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError","title":"acknowledge()"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend.close_connection","text":"Override this function if you want to use some finalizer code to shutdown your backend in a clean way Source code in melange/backends/interfaces.py def close_connection ( self ) -> None : \"\"\" Override this function if you want to use some finalizer code to shutdown your backend in a clean way \"\"\" pass","title":"close_connection()"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend.declare_queue","text":"Creates a queue named queue_name if it does not exist. with default settings. Parameters: Name Type Description Default queue_name str the name of the queue to create required *topics_to_bind Topic if provided, creates all these topics and subscribes the created queue to them () dead_letter_queue_name Optional[str] if provided, create a dead letter queue attached to the created queue_name . None **kwargs Any {} Returns: Type Description Tuple[melange.backends.interfaces.Queue, Optional[melange.backends.interfaces.Queue]] A tuple with the created queue and the dead letter queue (if applies) Source code in melange/backends/interfaces.py def declare_queue ( self , queue_name : str , * topics_to_bind : Topic , dead_letter_queue_name : Optional [ str ] = None , ** kwargs : Any ) -> Tuple [ Queue , Optional [ Queue ]]: \"\"\" Creates a queue named `queue_name` if it does not exist. with default settings. Args: queue_name: the name of the queue to create *topics_to_bind: if provided, creates all these topics and subscribes the created queue to them dead_letter_queue_name: if provided, create a dead letter queue attached to the created `queue_name`. **kwargs: Returns: A tuple with the created queue and the dead letter queue (if applies) \"\"\" raise NotImplementedError","title":"declare_queue()"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend.declare_topic","text":"Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required Source code in melange/backends/interfaces.py def declare_topic ( self , topic_name : str ) -> Topic : \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the backend, so what you return as a topic will be passed in next calls to the backend where a topic is required \"\"\" raise NotImplementedError","title":"declare_topic()"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend.delete_queue","text":"Deletes the queue Source code in melange/backends/interfaces.py def delete_queue ( self , queue : Queue ) -> None : \"\"\" Deletes the queue \"\"\" raise NotImplementedError","title":"delete_queue()"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend.delete_topic","text":"Deletes the topic Source code in melange/backends/interfaces.py def delete_topic ( self , topic : Topic ) -> None : \"\"\" Deletes the topic \"\"\" raise NotImplementedError","title":"delete_topic()"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend.get_queue","text":"Gets the queue with the name queue_name . Parameters: Name Type Description Default queue_name str the name of the queue to retrieve required Returns: Type Description Queue A Queue object that represents the created the queue Source code in melange/backends/interfaces.py def get_queue ( self , queue_name : str ) -> Queue : \"\"\" Gets the queue with the name `queue_name`. Args: queue_name: the name of the queue to retrieve Returns: A `Queue` object that represents the created the queue \"\"\" raise NotImplementedError","title":"get_queue()"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend.publish","text":"Publishes the content to the topic. The content must be a string (which is the json representation of an event) Source code in melange/backends/interfaces.py def publish ( self , content : str , topic : Topic , event_type_name : str , extra_attributes : Optional [ Dict ] = None , ) -> None : \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError","title":"publish()"},{"location":"components/messaging-backends/#melange.backends.interfaces.MessagingBackend.retrieve_messages","text":"Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process Source code in melange/backends/interfaces.py def retrieve_messages ( self , queue : Queue , attempt_id : Optional [ str ] = None ) -> List [ Message ]: \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError","title":"retrieve_messages()"},{"location":"components/publishers/","text":"Publishers Publishers, as implied by the name, publish messages to a message broker, which are then propagated/stored into a queue for consumers/subscribers to process. You can publish messages to queues or topics. Publishing to a queue Publishing a message to a queue makes this message available to a single consumer (that's the concept of a queue after all). To do that, build an instance of the QueuePublisher class and call the publish method with your message: from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = QueuePublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) The QueuePublisher requires a backend and a serializer as constructor parameters. The serializer is necessary to properly serialize and send the message to the messaging backend. TIP: In a production project where you would have a proper dependency injection framework in place (e.g. pinject ), you could instantiate the Publisher once and provide that instance through your application Publishing to a topic Publishing a message to a topic works exactly the same way as publishing to a queue, but it will work with the Fanout pattern to distribute the message to several subscribers of that topic. To do that, build an instance of the TopicPublisher class and call the publish method with your message: from melange.message_publisher import TopicPublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = TopicPublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-topic\" , message ) print ( \"Message sent successfully!\" ) As you can appreciate it works exactly the same way as publishing to a queue, the only difference happens behind the scenes.","title":"Publishers"},{"location":"components/publishers/#publishers","text":"Publishers, as implied by the name, publish messages to a message broker, which are then propagated/stored into a queue for consumers/subscribers to process. You can publish messages to queues or topics.","title":"Publishers"},{"location":"components/publishers/#publishing-to-a-queue","text":"Publishing a message to a queue makes this message available to a single consumer (that's the concept of a queue after all). To do that, build an instance of the QueuePublisher class and call the publish method with your message: from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = QueuePublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) The QueuePublisher requires a backend and a serializer as constructor parameters. The serializer is necessary to properly serialize and send the message to the messaging backend. TIP: In a production project where you would have a proper dependency injection framework in place (e.g. pinject ), you could instantiate the Publisher once and provide that instance through your application","title":"Publishing to a queue"},{"location":"components/publishers/#publishing-to-a-topic","text":"Publishing a message to a topic works exactly the same way as publishing to a queue, but it will work with the Fanout pattern to distribute the message to several subscribers of that topic. To do that, build an instance of the TopicPublisher class and call the publish method with your message: from melange.message_publisher import TopicPublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = TopicPublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-topic\" , message ) print ( \"Message sent successfully!\" ) As you can appreciate it works exactly the same way as publishing to a queue, the only difference happens behind the scenes.","title":"Publishing to a topic"},{"location":"components/serializers/","text":"Serializers Serializers are the component that translates (serializes) your python objects into a string that can be sent through the messaging infrastructure, and then translates it (deserializes) that string back to the python object. Melange is bundled with two serializers: a JSONSerializer to serialize python dictionaries and a PickleSerializer that will serialize any python object, but will only be deserializable from another python process and it's generally regarded as unsafe). When instantiating a publisher or a consumer you need to pass a list of serializers. Melange, upon sending or receiving messages, will select the serializer that best matches the one that can serialize and deserialize it. TODO: Implement the serializer selector from a list Creating your own serializers To create your own serializer, you need to inherit the class MessageSerializer and implement the methods manifest , deserialize and serialize . This is the MessageSerializer interface: MessageSerializer ( Generic ) Base interface to inherit for all the serializers of the platform Source code in melange/serializers/interfaces.py class MessageSerializer ( Generic [ T ]): \"\"\" Base interface to inherit for all the serializers of the platform \"\"\" def manifest ( self , data : T ) -> str : return \"\" def deserialize ( self , data : str , manifest : Optional [ str ] = None ) -> T : pass def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass serialize ( self , data ) Serializes and object to a string representation Source code in melange/serializers/interfaces.py def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass Some ideas of custom serializers: A protocol buffer serializer: Protocol Buffers (or protobuf for short) is a fast and compact serializing technology. In some projects where Melange is used in production such serializer has been implemented successfully.","title":"Serializers"},{"location":"components/serializers/#serializers","text":"Serializers are the component that translates (serializes) your python objects into a string that can be sent through the messaging infrastructure, and then translates it (deserializes) that string back to the python object. Melange is bundled with two serializers: a JSONSerializer to serialize python dictionaries and a PickleSerializer that will serialize any python object, but will only be deserializable from another python process and it's generally regarded as unsafe). When instantiating a publisher or a consumer you need to pass a list of serializers. Melange, upon sending or receiving messages, will select the serializer that best matches the one that can serialize and deserialize it. TODO: Implement the serializer selector from a list","title":"Serializers"},{"location":"components/serializers/#creating-your-own-serializers","text":"To create your own serializer, you need to inherit the class MessageSerializer and implement the methods manifest , deserialize and serialize . This is the MessageSerializer interface:","title":"Creating your own serializers"},{"location":"components/serializers/#melange.serializers.interfaces.MessageSerializer","text":"Base interface to inherit for all the serializers of the platform Source code in melange/serializers/interfaces.py class MessageSerializer ( Generic [ T ]): \"\"\" Base interface to inherit for all the serializers of the platform \"\"\" def manifest ( self , data : T ) -> str : return \"\" def deserialize ( self , data : str , manifest : Optional [ str ] = None ) -> T : pass def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass","title":"MessageSerializer"},{"location":"components/serializers/#melange.serializers.interfaces.MessageSerializer.serialize","text":"Serializes and object to a string representation Source code in melange/serializers/interfaces.py def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass Some ideas of custom serializers: A protocol buffer serializer: Protocol Buffers (or protobuf for short) is a fast and compact serializing technology. In some projects where Melange is used in production such serializer has been implemented successfully.","title":"serialize()"},{"location":"examples/payment-service/","text":"Payment Service TODO","title":"Payment service"},{"location":"examples/payment-service/#payment-service","text":"TODO","title":"Payment Service"},{"location":"examples/saga/","text":"Saga TODO","title":"Saga choreography"},{"location":"examples/saga/#saga","text":"TODO","title":"Saga"},{"location":"tutorial/getting-started/","text":"Tutorial - Getting started Event-driven architectures work with the Publish/Subscribe pattern to achieve decoupling. With this pattern, publishers and subscribers do not know about each other while they can exchange information among them. In order to achieve this and communicate effectively a mediator, or better said, a Message Broker is required to transfer messages from publishers to subscribers. Clients can subscribe this broker, waiting for events they are interested in, or publish messages so that the broker can distribute these messages appropriately. This tutorial assumes that you have basic understanding of the pub/sub mechanics. If not, there are a whole bunch of resources to get your feet wet on the topic. Also it's good to have docker installed since we are going to spin up local infrastructure to serve as a messaging broker. Choosing a Messaging Backend A messaging backend is the infrastructure where your messages are going to be published and consumed. In this tutorial we are going to use ElasticMQ as our messaging backend. Basically spinning up an ElasticMQ (for example with docker-compose ) in your machine will provide you with an SQS-like infrastructure to use with boto, which makes it ideal for testing and for the sake of this tutorial. You could follow the instructions in the ElasticMQ project to install it to your local machine. Though the quickest route is to launch the docker image: docker run -p 9324:9324 -p 9325:9325 softwaremill/elasticmq-native This will start ElasticMQ in the port 9324 in localhost , ready to be used. Creating a queue Before using a queue you need to create it. Put the following code snippet into a file called create_queue.py and execute it to create the queue: from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.backends.factory import MessagingBackendFactory backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"melangetutorial-queue\" ) Publishing messages Publishing messages to a queue with Melange is easy. Just create an instance of the message publisher and publish the message. Put the following code snippet into a file called publish_example.py : from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = QueuePublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) Once you run this code it will publish a message MyTestMessage with the contents Hello World in the queue melangetutorial-queue . You can send anything as long as your selected serializer can serialize/deserialize the object. Refer Serializers for further details. NOTE: For the sake of this tutorial you can use the PickleSerializer to serialize your messages. For production applications however you should probably use another type of serializer or create your own, since pickle is considered unsafe and only works with python consumers. Consuming messages It's good to publish messages, but they are worth nothing if nobody reads them. Therefore, we need a consumer that reads these messages and reacts to them. Put the following code snippet in a file called consumer-example.py and run it: from melange.consumers import Consumer , ConsumerHandler from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer from publish_example import MyTestMessage class MyConsumer ( SingleDispatchConsumer ): @listener def on_my_test_message_received ( self , event : MyTestMessage ) -> None : print ( event . message ) if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () consumer = MyConsumer () consumer_handler = SimpleConsumerHandler ( serializer , backend = backend , ) print ( \"Consuming...\" ) payment_consumer . consume_loop ( \"melangetutorial-queue\" ) Upon hitting the consume_loop method, the process will start polling the queue for new messages. Once it receives a message, as long as the message is of type MyTestMessage it will forward this message to the MyConsumer . If your infrastructure was set correctly, every time you run the publish_example.py script you will see a print with the message on the screen where the consumer is running. Congratulations! You just run your very first example of a Pub/Sub mechanism with Melange! NOTE: It's a good idea to have shared classes (like the MyTestMessage in the example) in its own python module (e.g. shared.py ) Where to go from here Although the exposed example is quite simple, it serves as the foundation to implement a number of use cases and distributed architectures with microservices. With Melange you can: Build a CQRS + Event sourcing architecture, where you publish your events to a queue or topic from the Command side and read those with a consumer from the Read side to create your data projections. Build choreography Sagas for long-running processes which can span several transactions. Implement microservices which consume messages from a queue to do their job (e.g. an staticstics microservice that reacts to a OrderCreated event and increments a counter to track how many orders your system has). We have not covered the case of topics. Refer to Publishers for further details. In addition, Melange is bundled with a consumer that works with a python application. But the consumer can be implemented in any language and any technology that can read messages from your queue (AWS Lambda, Azure functions, a NodeJS app...)","title":"Tutorial - Getting started"},{"location":"tutorial/getting-started/#tutorial-getting-started","text":"Event-driven architectures work with the Publish/Subscribe pattern to achieve decoupling. With this pattern, publishers and subscribers do not know about each other while they can exchange information among them. In order to achieve this and communicate effectively a mediator, or better said, a Message Broker is required to transfer messages from publishers to subscribers. Clients can subscribe this broker, waiting for events they are interested in, or publish messages so that the broker can distribute these messages appropriately. This tutorial assumes that you have basic understanding of the pub/sub mechanics. If not, there are a whole bunch of resources to get your feet wet on the topic. Also it's good to have docker installed since we are going to spin up local infrastructure to serve as a messaging broker.","title":"Tutorial - Getting started"},{"location":"tutorial/getting-started/#choosing-a-messaging-backend","text":"A messaging backend is the infrastructure where your messages are going to be published and consumed. In this tutorial we are going to use ElasticMQ as our messaging backend. Basically spinning up an ElasticMQ (for example with docker-compose ) in your machine will provide you with an SQS-like infrastructure to use with boto, which makes it ideal for testing and for the sake of this tutorial. You could follow the instructions in the ElasticMQ project to install it to your local machine. Though the quickest route is to launch the docker image: docker run -p 9324:9324 -p 9325:9325 softwaremill/elasticmq-native This will start ElasticMQ in the port 9324 in localhost , ready to be used.","title":"Choosing a Messaging Backend"},{"location":"tutorial/getting-started/#creating-a-queue","text":"Before using a queue you need to create it. Put the following code snippet into a file called create_queue.py and execute it to create the queue: from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.backends.factory import MessagingBackendFactory backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"melangetutorial-queue\" )","title":"Creating a queue"},{"location":"tutorial/getting-started/#publishing-messages","text":"Publishing messages to a queue with Melange is easy. Just create an instance of the message publisher and publish the message. Put the following code snippet into a file called publish_example.py : from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = QueuePublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) Once you run this code it will publish a message MyTestMessage with the contents Hello World in the queue melangetutorial-queue . You can send anything as long as your selected serializer can serialize/deserialize the object. Refer Serializers for further details. NOTE: For the sake of this tutorial you can use the PickleSerializer to serialize your messages. For production applications however you should probably use another type of serializer or create your own, since pickle is considered unsafe and only works with python consumers.","title":"Publishing messages"},{"location":"tutorial/getting-started/#consuming-messages","text":"It's good to publish messages, but they are worth nothing if nobody reads them. Therefore, we need a consumer that reads these messages and reacts to them. Put the following code snippet in a file called consumer-example.py and run it: from melange.consumers import Consumer , ConsumerHandler from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer from publish_example import MyTestMessage class MyConsumer ( SingleDispatchConsumer ): @listener def on_my_test_message_received ( self , event : MyTestMessage ) -> None : print ( event . message ) if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () consumer = MyConsumer () consumer_handler = SimpleConsumerHandler ( serializer , backend = backend , ) print ( \"Consuming...\" ) payment_consumer . consume_loop ( \"melangetutorial-queue\" ) Upon hitting the consume_loop method, the process will start polling the queue for new messages. Once it receives a message, as long as the message is of type MyTestMessage it will forward this message to the MyConsumer . If your infrastructure was set correctly, every time you run the publish_example.py script you will see a print with the message on the screen where the consumer is running. Congratulations! You just run your very first example of a Pub/Sub mechanism with Melange! NOTE: It's a good idea to have shared classes (like the MyTestMessage in the example) in its own python module (e.g. shared.py )","title":"Consuming messages"},{"location":"tutorial/getting-started/#where-to-go-from-here","text":"Although the exposed example is quite simple, it serves as the foundation to implement a number of use cases and distributed architectures with microservices. With Melange you can: Build a CQRS + Event sourcing architecture, where you publish your events to a queue or topic from the Command side and read those with a consumer from the Read side to create your data projections. Build choreography Sagas for long-running processes which can span several transactions. Implement microservices which consume messages from a queue to do their job (e.g. an staticstics microservice that reacts to a OrderCreated event and increments a counter to track how many orders your system has). We have not covered the case of topics. Refer to Publishers for further details. In addition, Melange is bundled with a consumer that works with a python application. But the consumer can be implemented in any language and any technology that can read messages from your queue (AWS Lambda, Azure functions, a NodeJS app...)","title":"Where to go from here"}]}
{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Melange TODO: Update the documentation to match the latest version 7.0.0 The spice must flow! melange is a python messaging library for an easy inter-communication in distributed and microservices architectures. It offers a flexible, easy-to-use library to create distributed event-driven architectures using your preferred messaging infrastructure mechanism as a backend message broker to dispatch messages and achieve inter-communication among your microservices and other components. Its main selling point is the capability to greatly decouple and integrate REST apis, AWS Lambda functions and console applications, emails, cellphones... The interface this library offers is very clean and tries to tightly follow the best practices from Vaughn Vernon's book Implementing Domain-Driven Design as well as the recommended design patterns when dealing with messaging on distributed architectures. Out of the box Melange supports the following message brokers as backend infrastructure: Amazon's AWS SNS (Simple Notification Service) + SQS (Simple Queue Service). RabbitMQ As time goes by more brokers will be added, but if you really want to use the simple and attractive interface Melange offers and your backend infrastructure is not listed (e.g. Kafka, Kinesis) you can implement your own driver. Read the section Adding your own messaging infrastructure for more information. If want to have a clean event-driven architecture with Domain Events, and its idea has been grabbed from Vaughn Vernon and his must-read book Implementing Domain-Driven Design (look at part 3 of these series if you want a quick look, or read this excellent article from Udi Dahan, founder of NServiceBus ). Installing pip install melange Getting started Event-driven architectures work with the Publish/Subscribe pattern to achieve decoupling. With this pattern, publishers and subscribers do not know about each other while they can exchange information among them. In order to achieve this and communicate effectively a mediator, or better said, a Message Broker is required to transfer messages from publishers to subscribers. Clients can subscribe this broker, waiting for events they are interested in, or publish messages so that the broker can distribute these messages appropriately. So, you will need two things to make this entire scene work: an Exchange Message Publisher and an Exchange Message SingleDispatchConsumer to send and receive messages respectively. But before getting your feet wet into this realm, first things first. You need to tell Melange which driver backend you want to use. Place this line in the initialization code of your application: # If you want to use AWS BackendManager . instance () . use_backend ( driver_name = 'aws' ) # If you want to use RabbitMQ. besides the driver_name parameter, the rest of the parameters are connection parameters # expressed as keyword arguments used by the pika library. Check pika documentation on the ConnectionParameters: # https://pika.readthedocs.io/en/0.10.0/modules/parameters.html BackendManager . instance () . use_backend ( driver_name = 'rabbitMQ' , ** connection_parameters ) This will configure Melange to use your message infrastructure as your messaging broker. Now, you are ready to work! NOTES: For Melange to properly with AWS work you'll require an AWS account configured in your system (environment variables, .aws/credentials file...) and you must have SNS + SQS permissions to create queues and topics, publish messages and perform subcriptions. Personally I prefer to use environment variables. These are the AWS environment variables you would need if you want to go with the environment variables route: # Extracted from http://docs.aws.amazon.com/cli/latest/userguide/cli-environment.html AWS_ACCESS_KEY_ID \u2013 AWS access key. AWS_SECRET_ACCESS_KEY \u2013 AWS secret key. Access and secret key variables override credentials stored in credential and config files. AWS_SESSION_TOKEN \u2013 Specify a session token if you are using temporary security credentials. Exchange Message Publisher The simplest application that can work with Melange is creating a Publisher which will send messages: message_publisher = TopicPublisher ( topic = 'some-topic-name' ) data = { 'event_type_name' : 'ProductAdded' , 'product_id' : 12345 , 'name' : 'Coolers' } message_publisher . publish ( data ) # NOTE: You can as well call publish with `message_publisher.publish(data, event_type_name='ProductAdded')` This piece of code will serialize the dictionary as JSON and send it to SNS to the topic some-topic-name . If the topic does not exist, it will be created (though no one will receive the message...). After that, all listeners subscribed to this topic will receive the message for further processing (be an AWS Lambda, an email address, an Exchange Message SingleDispatchConsumer, or any other compatible Amazon SNS subscriber). NOTE: The event_type_name property must exist in the dictionary. If it doesn't, you must supply the event_type_name through the event_type_name parameter from the publish method Exchange Message SingleDispatchConsumer After that, you may have in another separate project (be it a simple console application, django worker, another thread, etc) an Exchange Message SingleDispatchConsumer to receive these messages. And that consumer will require, at least, one listener to be of any use. The simplest implementation for that would be the following one, and you could place it in the initialization of your application: class SampleListener ( SingleDispatchConsumer ): def process ( self , event , ** kwargs ): print ( f \"I've received information about the product { event [ 'name' ] } \" ) def listens_to ( self ): return [ 'ProductAdded' ] message_consumer = ExchangeMessageDispatcher ( event_queue_name = 'my-queue' , topic_to_subscribe = 'some-topic-name' ) message_consumer . subscribe ( SampleListener ()) while True : message_consumer . consume_event () So, what's going on here? We've created a Listener that is interested in events of type ProductAdded and will react to those events when received from the Message Broker. Override process to provide behavior, and override listens_to to provide an array of event names you are interested in. We will attach this listener to a queue . A queue is a place where the messages received from SNS will be stored and available for the consumer application at his own time. To do so, we first create an ExchangeMessageDispatcher with a queue name and a topic. If the queue does not exist, it will create an SQS queue and subscribe it to the topic. Afterwards, you can subscribe an instance of your listener to the message consumer. Finally, you create a loop that will poll for new events and invoke the process method of your SingleDispatchConsumer for each event of the expected type it receives. Advanced usage What you've seen so far is the simplest application of Melange to easily create a simple Publish/Subscribe architecture. But you can go further than that and create a robust distributed application that fits with other architecture patterns like Hexagonal Architecture , Clean Architecture or CQRS , properly separating responsibilities. \"Stronger\" typing In the examples provided above, you were passing plain dictionaries, and the framework, through the event_type_name property could propertly distribute its message to the proper listeners. However some people (myself included) sometimes prefer to work with objects instead of dictionaries if possible. In that case you could declare your own EventMessage classes and use them with the publish/subscribe methods. The example above would be rewritten like this with this approach: Publisher: # In some file you would implement these classes class ProductAddedSchema ( EventSchema ): \"\"\" This is a marshmallow schema! \"\"\" product_id = fields . Int () name = fields . Str () @post_load def build ( self , data ): return ProductAdded ( data [ 'product_id' ], data [ 'name' ], data [ 'occurred_on' ]) class ProductAdded ( EventMessage ): event_type_name = 'ProductAdded' def __init__ ( self , product_id , name , occurred_on = None ): self . product_id = product_id self . name = name # In you initialization code you would call the following line: EventSerializer . instance () . register ( ProductAddedSchema ) message_publisher = TopicPublisher ( topic = 'some-topic-name' ) message_publisher . publish ( ProductAdded ( product_id = 12345 , name = 'Coolers' )) SingleDispatchConsumer: # In some file you would implement these classes # Bear in mind that these definition are placed in # another project, and you could define a different # ProductAdded event (e.g. without the name property, # maybe because you are not interested on that) class ProductAddedSchema ( EventSchema ): \"\"\" This is a marshmallow schema! \"\"\" product_id = fields . Int () name = fields . Str () @post_load def build ( self , data ): return ProductAdded ( data [ 'product_id' ], data [ 'name' ], data [ 'occurred_on' ]) class ProductAdded ( EventMessage ): event_type_name = 'ProductAdded' def __init__ ( self , product_id , name , occurred_on = None ): self . product_id = product_id self . name = name class SampleListener ( SingleDispatchConsumer ): def process ( self , event , ** kwargs ): # Note that I'm not accessing event properties by key, but as a regular object. # In fact event is of type ProductAdded, and this is possible thanks to marshmallow # post_load hook. If you don't add this hook, event would be again a dictionary print ( f \"I've received information about the product { event . name } \" ) def listens_to ( self ): return [ 'ProductAdded' ] # In you initialization code you would call the following line: EventSerializer . instance () . register ( ProductAddedSchema ) message_consumer = ExchangeMessageDispatcher ( event_queue_name = 'my-queue' , topic_to_subscribe = 'some-topic-name' ) message_consumer . subscribe ( SampleListener ()) # You can subscribe as many listeners as you want while True : message_consumer . consume_event () Note the Schema classes. These are marshmallow schemas, and they are used by the EventSerializer to serialize the EventMessage objects from/to JSON when publishing or receiving messages. Then in your initialization code you must register the Schema in order to work with Melange. The Schemas and their events are linked by naming convention, so a ProductAdded event will need a ProductAddedSchema schema, a UserRegistered event will require a UserRegisteredSchema schema... you get the idea. Note as well the occurred_on property. It's a datetime fields that tells you when the event did happen. This may be of use to you to guarantee correct ordering of message arrival on the Listeners. It's a bit more complicated to implement, but the resulting code is cleaner and more readable to another developer, and the intent, the event type and the property types for the event are clear and can be used as contract documentation for your listeners. Up to you and your needs/feelings. Threaded Exchange Message SingleDispatchConsumer The ThreadedExchangeMessageConsumer allows you to create a consumer that will poll the message queue on a separate thread. The ThreadedExchangeMessageConsumer inherits from python Thread class, so you can use them for your threading purposes. The consumer example above would be rewritten like this: class SampleListener ( SingleDispatchConsumer ): def process ( self , event , ** kwargs ): print ( f \"I've received information about the product { event [ 'name' ] } \" ) def listens_to ( self ): return [ 'ProductAdded' ] message_consumer = ThreadedExchangeMessageConsumer ( queue = 'my-queue' , topic = 'some-topic-name' ) message_consumer . subscribe ( SampleListener ()) message_consumer . start () print ( 'You can do other stuff from here, the consumer will poll events and call subscribers' ) print ( 'from a separate thread' ) Event Message de-duplication Distributed architectures are hard, complex and come with a good deal of burdens, but they are required to achieve levels of scalability and isolation harder to achieve on monolithic architectures. One of this issues is the possibility of of the same message being received twice by the listeners. Network failures, application crashes, etc... can cause this issue which, if not though or left undealt can cause your system to be out of sync and run in an inconsistent state. This is why you need to take measures. One of this measures is to, simply, write your listeners to be idempotent . This means that it does not matter how many times a listener is called, the result will be the same and it won't impact or leave the system into an inconsistent state. However, sometimes writing idempotent code is just not possible. You require message deduplication to account for this and ensure that a message won't be sent twice. You could use Amazon SQS FIFO Queues which they say they provide this message deduplication, though not only FIFO queues are more expensive than standard ones, but exactly-once delivery is just impossible . In Melange we have accounted for this with a Redis cache that will control that no message is delivered twice. In order for this to work you have to provide the following environment variables as configuration so that Melange can connect to your Redis database: ENVIRONMENT VARIABLE NAME Default Description CACHE_REDIS_HOST localhost The host of your Redis CACHE_REDIS_PORT 6379 The port of your Redis CACHE_REDIS_DB 0 The DB to use for your Redis CACHE_REDIS_PASSWORD The password of your Redis CACHE_NAMESPACE SimpleCache You can provide a namespace so that values created by Melange do not collide with each other If Melange is unable to connect to your Redis it will function normally but you won't enjoy the benefits of ensuring message deduplication, which may lead your distributed application in an inconsitent state. You're warned :). Domain-Driven Design In his book \"Implementing Domain-Driven Design\", in Chapter 8 when talking about Domain Events describes an implementation of a Domain Event Publisher . Domain Events are part of the ubiquitous language and part of your Domain, and your domain should be abstracted from implementation details like your messaging framework. This is why I decided to integrate here a DomainEventBus . The DomainEventBus is intended to be used inside your Domain Model as the mecanism to publish Domain Events and forward them to interested parties. DO NOT confuse this concept of Bus with Publish/Subscribe to a Message Broker like RabbitMQ or Amazon SNS+SQS. This bus lives in the same thread as the entity or domain service that implements your Domain Model. An example of use: class MySubscriber ( DomainSubscriber ): def process ( self , event ): print ( f \" { event . product_id }{ event . name } \" ) def listens_to ( self ): return [ ProductAddedDomainEvent ] DomainEventBus . instance () . reset () # Remember to always reset the bus prior to usage in the current thread DomainEventBus . instance () . subscribe ( MySubscriber ()) # ... inside your business logic at some point ... product_repository . add ( my_product ) DomainEventBus . instance () . publish ( ProductAddedDomainEvent ( my_product . id , my_product . name )) If you wanna learn more about how to do clean architectures and domain well isolated from your technology stack I advise, again, to read Implementing Domain-Driven Design from Vaughn Vernon and Clean Architecture from Uncle Bob Adding your own messaging infrastructure You can implement your own driver to use with Melange if you wish so and easily plug it in the library. You just need to create a driver class and either add it to the list of available drivers or directly use it. To create the driver class, you need to inherit from MessagingDriver and override all the methods from this class. The documentation of this class explains very well what should these methods accepts as parameters and return: class MessagingDriver : def __init__ ( self ): self . _finalizer = weakref . finalize ( self , self . close_connection ) def declare_topic ( self , topic_name ): \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the driver, so what you return as a topic will be passed in next calls to the driver where a topic is required \"\"\" raise NotImplementedError def declare_queue ( self , queue_name , topic_to_bind = None , dead_letter_queue_name = None ): \"\"\" Declares a queue with the name \"queue_name\". Optionally, this queue may be binded to the topic \"topic_to_bind\" and associated to a dead_letter_queue \"dead_letter_queue_name\" where messages that were unable to deliver will be placed. :param queue_name: The name of the queue to create :param topic_to_bind: The topic object where you will bind your queue :param dead_letter_queue_name: The name of the dead letter queue to create and associate to the queue \"queue_name\" :return: A tuple, with the first element being the object queue created, and the second element is the dead letter queue object. The type of the queue object is only relevant inside the context of the driver, so what you return as a queue will be passed in next calls to the driver where a queue is required \"\"\" raise NotImplementedError def retrieve_messages ( self , queue ): \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError def publish ( self , content , topic ): \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError def acknowledge ( self , message ): \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError def close_connection ( self ): \"\"\" Override this function if you want to use some finalizer code to shutdown your driver in a clean way \"\"\" pass def delete_queue ( self , queue ): \"\"\" Deletes the queue \"\"\" raise NotImplementedError def delete_topic ( self , topic ): \"\"\" Deletes the topic \"\"\" raise NotImplementedError Inspire yourself with the implementations of the AWSDriver and the RabbitMQDriver. After you created your own driver, you just need to tell the BackendManager to recognize your driver: driver = MyDriver () BackendManager . instance () . use_backend ( driver = driver ) Or if you want to register it into Melange and use it afterwards or create your own Melange plugin: driver = MyDriver () BackendManager . instance () . add_available_backends ( mydriver = MyDriver ) .... At some point later you would call : BackendManager . instance () . use_backend ( driver_name = \"mydriver\" ) Now Melange will use your driver as the backend message infrastructure. Other useful uses AWS Lambda functions Melange is great to communicate with AWS Lambda functions and integrate them with other lambdas or systems. You could: Use the MessagePublisher to publish events to SNS topics (which then could trigger other Lambdas/systems). Use the MessageConsumer on a schedule-job based lambda to dequeue one event from an SQS queue for processing. If the Lambda is triggered by SNS, SNS will wrap the message in a dictionary structure. You can deserialize the message by using the parse_event_from_sns function. Example of a Lambda function code: def handle_event ( message , context ): EventSerializer . instance () . register ( MyEventSchema , MyFooCreatedSchema ) event = parse_event_from_sns ( message ) # Here you can check whether the parsed event is the one expected by your Lambda function if not isinstance ( event , MyEvent ): raise Exception ( 'The passed event is not a MyEvent' ) # Your event-processing code here... do_work ( event ) message_publisher = MessagePublisher ( topic = 'some-topic' ) # This publish, depending on who is suscribed to the topic, will trigger other systems. event_to_publish = MyFooCreated () message_publisher . publish ( event_to_publish ) Interact with Django/Flask APIs SNS allows you to register endpoints on topics. You can use the MessagePublisher to publish messages to these SNS topics and SNS will send the messages to those endpoints, allowing you to seamlessly integrate your apis and other systems. Why the name 'Melange' The name \"Melange\" is a reference to the drug-spice from the sci-fi book saga \"Dune\", a spice which is only generated in a single planet in the universe (planet Dune) and every human depends on it. If the spice flows, then the spice can be controlled. He who controls the spice, controls the universe. The spice must flow. The analogy can be very well made on Events in a distributed architecture :) Logo Nature Vectors by Vecteezy","title":"Melange"},{"location":"#melange","text":"TODO: Update the documentation to match the latest version 7.0.0 The spice must flow! melange is a python messaging library for an easy inter-communication in distributed and microservices architectures. It offers a flexible, easy-to-use library to create distributed event-driven architectures using your preferred messaging infrastructure mechanism as a backend message broker to dispatch messages and achieve inter-communication among your microservices and other components. Its main selling point is the capability to greatly decouple and integrate REST apis, AWS Lambda functions and console applications, emails, cellphones... The interface this library offers is very clean and tries to tightly follow the best practices from Vaughn Vernon's book Implementing Domain-Driven Design as well as the recommended design patterns when dealing with messaging on distributed architectures. Out of the box Melange supports the following message brokers as backend infrastructure: Amazon's AWS SNS (Simple Notification Service) + SQS (Simple Queue Service). RabbitMQ As time goes by more brokers will be added, but if you really want to use the simple and attractive interface Melange offers and your backend infrastructure is not listed (e.g. Kafka, Kinesis) you can implement your own driver. Read the section Adding your own messaging infrastructure for more information. If want to have a clean event-driven architecture with Domain Events, and its idea has been grabbed from Vaughn Vernon and his must-read book Implementing Domain-Driven Design (look at part 3 of these series if you want a quick look, or read this excellent article from Udi Dahan, founder of NServiceBus ).","title":"Melange"},{"location":"#installing","text":"pip install melange","title":"Installing"},{"location":"#getting-started","text":"Event-driven architectures work with the Publish/Subscribe pattern to achieve decoupling. With this pattern, publishers and subscribers do not know about each other while they can exchange information among them. In order to achieve this and communicate effectively a mediator, or better said, a Message Broker is required to transfer messages from publishers to subscribers. Clients can subscribe this broker, waiting for events they are interested in, or publish messages so that the broker can distribute these messages appropriately. So, you will need two things to make this entire scene work: an Exchange Message Publisher and an Exchange Message SingleDispatchConsumer to send and receive messages respectively. But before getting your feet wet into this realm, first things first. You need to tell Melange which driver backend you want to use. Place this line in the initialization code of your application: # If you want to use AWS BackendManager . instance () . use_backend ( driver_name = 'aws' ) # If you want to use RabbitMQ. besides the driver_name parameter, the rest of the parameters are connection parameters # expressed as keyword arguments used by the pika library. Check pika documentation on the ConnectionParameters: # https://pika.readthedocs.io/en/0.10.0/modules/parameters.html BackendManager . instance () . use_backend ( driver_name = 'rabbitMQ' , ** connection_parameters ) This will configure Melange to use your message infrastructure as your messaging broker. Now, you are ready to work! NOTES: For Melange to properly with AWS work you'll require an AWS account configured in your system (environment variables, .aws/credentials file...) and you must have SNS + SQS permissions to create queues and topics, publish messages and perform subcriptions. Personally I prefer to use environment variables. These are the AWS environment variables you would need if you want to go with the environment variables route: # Extracted from http://docs.aws.amazon.com/cli/latest/userguide/cli-environment.html AWS_ACCESS_KEY_ID \u2013 AWS access key. AWS_SECRET_ACCESS_KEY \u2013 AWS secret key. Access and secret key variables override credentials stored in credential and config files. AWS_SESSION_TOKEN \u2013 Specify a session token if you are using temporary security credentials.","title":"Getting started"},{"location":"#exchange-message-publisher","text":"The simplest application that can work with Melange is creating a Publisher which will send messages: message_publisher = TopicPublisher ( topic = 'some-topic-name' ) data = { 'event_type_name' : 'ProductAdded' , 'product_id' : 12345 , 'name' : 'Coolers' } message_publisher . publish ( data ) # NOTE: You can as well call publish with `message_publisher.publish(data, event_type_name='ProductAdded')` This piece of code will serialize the dictionary as JSON and send it to SNS to the topic some-topic-name . If the topic does not exist, it will be created (though no one will receive the message...). After that, all listeners subscribed to this topic will receive the message for further processing (be an AWS Lambda, an email address, an Exchange Message SingleDispatchConsumer, or any other compatible Amazon SNS subscriber). NOTE: The event_type_name property must exist in the dictionary. If it doesn't, you must supply the event_type_name through the event_type_name parameter from the publish method","title":"Exchange Message Publisher"},{"location":"#exchange-message-singledispatchconsumer","text":"After that, you may have in another separate project (be it a simple console application, django worker, another thread, etc) an Exchange Message SingleDispatchConsumer to receive these messages. And that consumer will require, at least, one listener to be of any use. The simplest implementation for that would be the following one, and you could place it in the initialization of your application: class SampleListener ( SingleDispatchConsumer ): def process ( self , event , ** kwargs ): print ( f \"I've received information about the product { event [ 'name' ] } \" ) def listens_to ( self ): return [ 'ProductAdded' ] message_consumer = ExchangeMessageDispatcher ( event_queue_name = 'my-queue' , topic_to_subscribe = 'some-topic-name' ) message_consumer . subscribe ( SampleListener ()) while True : message_consumer . consume_event () So, what's going on here? We've created a Listener that is interested in events of type ProductAdded and will react to those events when received from the Message Broker. Override process to provide behavior, and override listens_to to provide an array of event names you are interested in. We will attach this listener to a queue . A queue is a place where the messages received from SNS will be stored and available for the consumer application at his own time. To do so, we first create an ExchangeMessageDispatcher with a queue name and a topic. If the queue does not exist, it will create an SQS queue and subscribe it to the topic. Afterwards, you can subscribe an instance of your listener to the message consumer. Finally, you create a loop that will poll for new events and invoke the process method of your SingleDispatchConsumer for each event of the expected type it receives.","title":"Exchange Message SingleDispatchConsumer"},{"location":"#advanced-usage","text":"What you've seen so far is the simplest application of Melange to easily create a simple Publish/Subscribe architecture. But you can go further than that and create a robust distributed application that fits with other architecture patterns like Hexagonal Architecture , Clean Architecture or CQRS , properly separating responsibilities.","title":"Advanced usage"},{"location":"#stronger-typing","text":"In the examples provided above, you were passing plain dictionaries, and the framework, through the event_type_name property could propertly distribute its message to the proper listeners. However some people (myself included) sometimes prefer to work with objects instead of dictionaries if possible. In that case you could declare your own EventMessage classes and use them with the publish/subscribe methods. The example above would be rewritten like this with this approach: Publisher: # In some file you would implement these classes class ProductAddedSchema ( EventSchema ): \"\"\" This is a marshmallow schema! \"\"\" product_id = fields . Int () name = fields . Str () @post_load def build ( self , data ): return ProductAdded ( data [ 'product_id' ], data [ 'name' ], data [ 'occurred_on' ]) class ProductAdded ( EventMessage ): event_type_name = 'ProductAdded' def __init__ ( self , product_id , name , occurred_on = None ): self . product_id = product_id self . name = name # In you initialization code you would call the following line: EventSerializer . instance () . register ( ProductAddedSchema ) message_publisher = TopicPublisher ( topic = 'some-topic-name' ) message_publisher . publish ( ProductAdded ( product_id = 12345 , name = 'Coolers' )) SingleDispatchConsumer: # In some file you would implement these classes # Bear in mind that these definition are placed in # another project, and you could define a different # ProductAdded event (e.g. without the name property, # maybe because you are not interested on that) class ProductAddedSchema ( EventSchema ): \"\"\" This is a marshmallow schema! \"\"\" product_id = fields . Int () name = fields . Str () @post_load def build ( self , data ): return ProductAdded ( data [ 'product_id' ], data [ 'name' ], data [ 'occurred_on' ]) class ProductAdded ( EventMessage ): event_type_name = 'ProductAdded' def __init__ ( self , product_id , name , occurred_on = None ): self . product_id = product_id self . name = name class SampleListener ( SingleDispatchConsumer ): def process ( self , event , ** kwargs ): # Note that I'm not accessing event properties by key, but as a regular object. # In fact event is of type ProductAdded, and this is possible thanks to marshmallow # post_load hook. If you don't add this hook, event would be again a dictionary print ( f \"I've received information about the product { event . name } \" ) def listens_to ( self ): return [ 'ProductAdded' ] # In you initialization code you would call the following line: EventSerializer . instance () . register ( ProductAddedSchema ) message_consumer = ExchangeMessageDispatcher ( event_queue_name = 'my-queue' , topic_to_subscribe = 'some-topic-name' ) message_consumer . subscribe ( SampleListener ()) # You can subscribe as many listeners as you want while True : message_consumer . consume_event () Note the Schema classes. These are marshmallow schemas, and they are used by the EventSerializer to serialize the EventMessage objects from/to JSON when publishing or receiving messages. Then in your initialization code you must register the Schema in order to work with Melange. The Schemas and their events are linked by naming convention, so a ProductAdded event will need a ProductAddedSchema schema, a UserRegistered event will require a UserRegisteredSchema schema... you get the idea. Note as well the occurred_on property. It's a datetime fields that tells you when the event did happen. This may be of use to you to guarantee correct ordering of message arrival on the Listeners. It's a bit more complicated to implement, but the resulting code is cleaner and more readable to another developer, and the intent, the event type and the property types for the event are clear and can be used as contract documentation for your listeners. Up to you and your needs/feelings.","title":"\"Stronger\" typing"},{"location":"#threaded-exchange-message-singledispatchconsumer","text":"The ThreadedExchangeMessageConsumer allows you to create a consumer that will poll the message queue on a separate thread. The ThreadedExchangeMessageConsumer inherits from python Thread class, so you can use them for your threading purposes. The consumer example above would be rewritten like this: class SampleListener ( SingleDispatchConsumer ): def process ( self , event , ** kwargs ): print ( f \"I've received information about the product { event [ 'name' ] } \" ) def listens_to ( self ): return [ 'ProductAdded' ] message_consumer = ThreadedExchangeMessageConsumer ( queue = 'my-queue' , topic = 'some-topic-name' ) message_consumer . subscribe ( SampleListener ()) message_consumer . start () print ( 'You can do other stuff from here, the consumer will poll events and call subscribers' ) print ( 'from a separate thread' )","title":"Threaded Exchange Message SingleDispatchConsumer"},{"location":"#event-message-de-duplication","text":"Distributed architectures are hard, complex and come with a good deal of burdens, but they are required to achieve levels of scalability and isolation harder to achieve on monolithic architectures. One of this issues is the possibility of of the same message being received twice by the listeners. Network failures, application crashes, etc... can cause this issue which, if not though or left undealt can cause your system to be out of sync and run in an inconsistent state. This is why you need to take measures. One of this measures is to, simply, write your listeners to be idempotent . This means that it does not matter how many times a listener is called, the result will be the same and it won't impact or leave the system into an inconsistent state. However, sometimes writing idempotent code is just not possible. You require message deduplication to account for this and ensure that a message won't be sent twice. You could use Amazon SQS FIFO Queues which they say they provide this message deduplication, though not only FIFO queues are more expensive than standard ones, but exactly-once delivery is just impossible . In Melange we have accounted for this with a Redis cache that will control that no message is delivered twice. In order for this to work you have to provide the following environment variables as configuration so that Melange can connect to your Redis database: ENVIRONMENT VARIABLE NAME Default Description CACHE_REDIS_HOST localhost The host of your Redis CACHE_REDIS_PORT 6379 The port of your Redis CACHE_REDIS_DB 0 The DB to use for your Redis CACHE_REDIS_PASSWORD The password of your Redis CACHE_NAMESPACE SimpleCache You can provide a namespace so that values created by Melange do not collide with each other If Melange is unable to connect to your Redis it will function normally but you won't enjoy the benefits of ensuring message deduplication, which may lead your distributed application in an inconsitent state. You're warned :).","title":"Event Message de-duplication"},{"location":"#domain-driven-design","text":"In his book \"Implementing Domain-Driven Design\", in Chapter 8 when talking about Domain Events describes an implementation of a Domain Event Publisher . Domain Events are part of the ubiquitous language and part of your Domain, and your domain should be abstracted from implementation details like your messaging framework. This is why I decided to integrate here a DomainEventBus . The DomainEventBus is intended to be used inside your Domain Model as the mecanism to publish Domain Events and forward them to interested parties. DO NOT confuse this concept of Bus with Publish/Subscribe to a Message Broker like RabbitMQ or Amazon SNS+SQS. This bus lives in the same thread as the entity or domain service that implements your Domain Model. An example of use: class MySubscriber ( DomainSubscriber ): def process ( self , event ): print ( f \" { event . product_id }{ event . name } \" ) def listens_to ( self ): return [ ProductAddedDomainEvent ] DomainEventBus . instance () . reset () # Remember to always reset the bus prior to usage in the current thread DomainEventBus . instance () . subscribe ( MySubscriber ()) # ... inside your business logic at some point ... product_repository . add ( my_product ) DomainEventBus . instance () . publish ( ProductAddedDomainEvent ( my_product . id , my_product . name )) If you wanna learn more about how to do clean architectures and domain well isolated from your technology stack I advise, again, to read Implementing Domain-Driven Design from Vaughn Vernon and Clean Architecture from Uncle Bob","title":"Domain-Driven Design"},{"location":"#adding-your-own-messaging-infrastructure","text":"You can implement your own driver to use with Melange if you wish so and easily plug it in the library. You just need to create a driver class and either add it to the list of available drivers or directly use it. To create the driver class, you need to inherit from MessagingDriver and override all the methods from this class. The documentation of this class explains very well what should these methods accepts as parameters and return: class MessagingDriver : def __init__ ( self ): self . _finalizer = weakref . finalize ( self , self . close_connection ) def declare_topic ( self , topic_name ): \"\"\" Declares a topic exchange with the name \"topic name\" and returns an object that represent the topic :param topic_name: The name of the topic to create :return: An object that represents a topic. The type of the object is only relevant inside the context of the driver, so what you return as a topic will be passed in next calls to the driver where a topic is required \"\"\" raise NotImplementedError def declare_queue ( self , queue_name , topic_to_bind = None , dead_letter_queue_name = None ): \"\"\" Declares a queue with the name \"queue_name\". Optionally, this queue may be binded to the topic \"topic_to_bind\" and associated to a dead_letter_queue \"dead_letter_queue_name\" where messages that were unable to deliver will be placed. :param queue_name: The name of the queue to create :param topic_to_bind: The topic object where you will bind your queue :param dead_letter_queue_name: The name of the dead letter queue to create and associate to the queue \"queue_name\" :return: A tuple, with the first element being the object queue created, and the second element is the dead letter queue object. The type of the queue object is only relevant inside the context of the driver, so what you return as a queue will be passed in next calls to the driver where a queue is required \"\"\" raise NotImplementedError def retrieve_messages ( self , queue ): \"\"\" Returns a list of messages (instances of Message type) that have been received from the queue. :param queue: queue to poll :return: a list of messages to process \"\"\" raise NotImplementedError def publish ( self , content , topic ): \"\"\" Publishes the content to the topic. The content must be a string (which is the json representation of an event) \"\"\" raise NotImplementedError def acknowledge ( self , message ): \"\"\" Acknowledges a message so that it won't be redelivered by the messaging infrastructure in the future \"\"\" raise NotImplementedError def close_connection ( self ): \"\"\" Override this function if you want to use some finalizer code to shutdown your driver in a clean way \"\"\" pass def delete_queue ( self , queue ): \"\"\" Deletes the queue \"\"\" raise NotImplementedError def delete_topic ( self , topic ): \"\"\" Deletes the topic \"\"\" raise NotImplementedError Inspire yourself with the implementations of the AWSDriver and the RabbitMQDriver. After you created your own driver, you just need to tell the BackendManager to recognize your driver: driver = MyDriver () BackendManager . instance () . use_backend ( driver = driver ) Or if you want to register it into Melange and use it afterwards or create your own Melange plugin: driver = MyDriver () BackendManager . instance () . add_available_backends ( mydriver = MyDriver ) .... At some point later you would call : BackendManager . instance () . use_backend ( driver_name = \"mydriver\" ) Now Melange will use your driver as the backend message infrastructure.","title":"Adding your own messaging infrastructure"},{"location":"#other-useful-uses","text":"","title":"Other useful uses"},{"location":"#aws-lambda-functions","text":"Melange is great to communicate with AWS Lambda functions and integrate them with other lambdas or systems. You could: Use the MessagePublisher to publish events to SNS topics (which then could trigger other Lambdas/systems). Use the MessageConsumer on a schedule-job based lambda to dequeue one event from an SQS queue for processing. If the Lambda is triggered by SNS, SNS will wrap the message in a dictionary structure. You can deserialize the message by using the parse_event_from_sns function. Example of a Lambda function code: def handle_event ( message , context ): EventSerializer . instance () . register ( MyEventSchema , MyFooCreatedSchema ) event = parse_event_from_sns ( message ) # Here you can check whether the parsed event is the one expected by your Lambda function if not isinstance ( event , MyEvent ): raise Exception ( 'The passed event is not a MyEvent' ) # Your event-processing code here... do_work ( event ) message_publisher = MessagePublisher ( topic = 'some-topic' ) # This publish, depending on who is suscribed to the topic, will trigger other systems. event_to_publish = MyFooCreated () message_publisher . publish ( event_to_publish )","title":"AWS Lambda functions"},{"location":"#interact-with-djangoflask-apis","text":"SNS allows you to register endpoints on topics. You can use the MessagePublisher to publish messages to these SNS topics and SNS will send the messages to those endpoints, allowing you to seamlessly integrate your apis and other systems.","title":"Interact with Django/Flask APIs"},{"location":"#why-the-name-melange","text":"The name \"Melange\" is a reference to the drug-spice from the sci-fi book saga \"Dune\", a spice which is only generated in a single planet in the universe (planet Dune) and every human depends on it. If the spice flows, then the spice can be controlled. He who controls the spice, controls the universe. The spice must flow. The analogy can be very well made on Events in a distributed architecture :) Logo Nature Vectors by Vecteezy","title":"Why the name 'Melange'"},{"location":"advanced-topics/","text":"","title":"Advanced topics"},{"location":"api-reference/","text":"API reference TopicPublisher Some documentation here is in order Source code in melange/message_publisher.py class TopicPublisher : \"\"\" Some documentation here is in order \"\"\" def __init__ ( self , message_serializer : MessageSerializer , backend : Optional [ MessagingBackend ] = None , ) -> None : self . _backend = backend or BackendManager () . get_backend () self . message_serializer = message_serializer def publish ( self , topic_name : str , data : Any , ** extra_attributes : Any ) -> bool : topic = self . _backend . declare_topic ( topic_name ) content = self . message_serializer . serialize ( data ) manifest = self . message_serializer . manifest ( data ) self . _backend . publish ( content , topic , event_type_name = manifest , extra_attributes = extra_attributes , ) return True MessagingBackendFactory","title":"API reference"},{"location":"api-reference/#api-reference","text":"","title":"API reference"},{"location":"api-reference/#melange.message_publisher.TopicPublisher","text":"Some documentation here is in order Source code in melange/message_publisher.py class TopicPublisher : \"\"\" Some documentation here is in order \"\"\" def __init__ ( self , message_serializer : MessageSerializer , backend : Optional [ MessagingBackend ] = None , ) -> None : self . _backend = backend or BackendManager () . get_backend () self . message_serializer = message_serializer def publish ( self , topic_name : str , data : Any , ** extra_attributes : Any ) -> bool : topic = self . _backend . declare_topic ( topic_name ) content = self . message_serializer . serialize ( data ) manifest = self . message_serializer . manifest ( data ) self . _backend . publish ( content , topic , event_type_name = manifest , extra_attributes = extra_attributes , ) return True","title":"TopicPublisher"},{"location":"api-reference/#messagingbackendfactory","text":"","title":"MessagingBackendFactory"},{"location":"extending/","text":"","title":"Extending Melange"},{"location":"factory/","text":"Factory Although you could set up your own topics and queues in your infrastructure (e.g. by using terraform) you can rely on Personally I have no strong feelings over defining your queues and topics through an infrastructure-as-code framework or letting the application create it's own queues and topics (as long as it has the appropriate permissions to do so). In any case, Melange offers a factory to create queues and topics for you with the MessagingBackendFactory . The factory initialization methods are idempotent. If a queue or a topic already exist, they will keep the same queue or topic, but override any settings or customizations that you might have manually set in your PaaS platform. Creating a queue Let's say you'd wish to create an Amazon SQS queue to listen to the events for a payment service. You could invoke the factory as follows: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" ) This will create a FIFO queue payment-updates in your AWS account (remember to appropriately set the AWS variables since the SQS backend uses boto behind the scenes). You could also define a dead letter queue for messages that could not be delivered successfully: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" , dead_letter_queue_name = \"payment-updates.fifo\" ) Creating a topic Topics apply the fan-out pattern to send the message to anyone who is subscribed to them. They are useful to decouple your consumers from your application so that they don't need to know who they are sending their messages to. With the factory you could create a topic like this: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_topic ( \"my-topic\" ) For the SQSBackend this will create an SNS topic. Creating a queue and subscribing it to several topics You could create a queue and immediately subscribe it to a number of topics: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" , \"my-topic-1\" , \"my-topic-2\" , \"my-topic-3\" , dead_letter_queue_name = \"payment-updates.fifo\" ) This will create the topics my-topic-1 , my-topic-2 and my-topic-3 , then create the payment-updates.fifo queue, and subscribe it to the aforementioned topics. It will create the dead letter queue too.","title":"Factory"},{"location":"factory/#factory","text":"Although you could set up your own topics and queues in your infrastructure (e.g. by using terraform) you can rely on Personally I have no strong feelings over defining your queues and topics through an infrastructure-as-code framework or letting the application create it's own queues and topics (as long as it has the appropriate permissions to do so). In any case, Melange offers a factory to create queues and topics for you with the MessagingBackendFactory . The factory initialization methods are idempotent. If a queue or a topic already exist, they will keep the same queue or topic, but override any settings or customizations that you might have manually set in your PaaS platform.","title":"Factory"},{"location":"factory/#creating-a-queue","text":"Let's say you'd wish to create an Amazon SQS queue to listen to the events for a payment service. You could invoke the factory as follows: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" ) This will create a FIFO queue payment-updates in your AWS account (remember to appropriately set the AWS variables since the SQS backend uses boto behind the scenes). You could also define a dead letter queue for messages that could not be delivered successfully: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" , dead_letter_queue_name = \"payment-updates.fifo\" )","title":"Creating a queue"},{"location":"factory/#creating-a-topic","text":"Topics apply the fan-out pattern to send the message to anyone who is subscribed to them. They are useful to decouple your consumers from your application so that they don't need to know who they are sending their messages to. With the factory you could create a topic like this: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_topic ( \"my-topic\" ) For the SQSBackend this will create an SNS topic.","title":"Creating a topic"},{"location":"factory/#creating-a-queue-and-subscribing-it-to-several-topics","text":"You could create a queue and immediately subscribe it to a number of topics: from melange.backends.sqs.sqs_backend import SQSBackend from melange.backends.factory import MessagingBackendFactory backend = SQSBackend () factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"payment-updates.fifo\" , \"my-topic-1\" , \"my-topic-2\" , \"my-topic-3\" , dead_letter_queue_name = \"payment-updates.fifo\" ) This will create the topics my-topic-1 , my-topic-2 and my-topic-3 , then create the payment-updates.fifo queue, and subscribe it to the aforementioned topics. It will create the dead letter queue too.","title":"Creating a queue and subscribing it to several topics"},{"location":"future-ideas/","text":"","title":"Future ideas"},{"location":"testing/","text":"Testing Any developer worth its salt does testing of some kind over the code they develop. Melange offers several utilities to help you test your publishers and consumers.","title":"Testing"},{"location":"testing/#testing","text":"Any developer worth its salt does testing of some kind over the code they develop. Melange offers several utilities to help you test your publishers and consumers.","title":"Testing"},{"location":"components/consumers/","text":"Consumers","title":"Consumers"},{"location":"components/consumers/#consumers","text":"","title":"Consumers"},{"location":"components/messaging-backends/","text":"Messaging backends SQS RabbitMQ Writing your own backend","title":"Messaging Backends"},{"location":"components/messaging-backends/#messaging-backends","text":"","title":"Messaging backends"},{"location":"components/messaging-backends/#sqs","text":"","title":"SQS"},{"location":"components/messaging-backends/#rabbitmq","text":"","title":"RabbitMQ"},{"location":"components/messaging-backends/#writing-your-own-backend","text":"","title":"Writing your own backend"},{"location":"components/publishers/","text":"Publishers Publishers, as implied by the name, publish messages to a message broker, which are then propagated/stored into a queue for consumers/subscribers to process. You can publish messages to queues or topics. Publishing to a queue Publishing a message to a queue makes this message available to a single consumer (that's the concept of a queue after all). To do that, build an instance of the QueuePublisher class and call the publish method with your message: from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = QueuePublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) The QueuePublisher requires a backend and a serializer as constructor parameters. The serializer is necessary to properly serialize and send the message to the messaging backend. TIP: In a production project where you would have a proper dependency injection framework in place (e.g. pinject ), you could instantiate the Publisher once and provide that instance through your application Publishing to a topic Publishing a message to a topic works exactly the same way as publishing to a queue, but it will work with the Fanout pattern to distribute the message to several subscribers of that topic. To do that, build an instance of the TopicPublisher class and call the publish method with your message: from melange.message_publisher import TopicPublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = TopicPublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-topic\" , message ) print ( \"Message sent successfully!\" ) As you can appreciate it works exactly the same way as publishing to a queue, the only difference happens behind the scenes.","title":"Publishers"},{"location":"components/publishers/#publishers","text":"Publishers, as implied by the name, publish messages to a message broker, which are then propagated/stored into a queue for consumers/subscribers to process. You can publish messages to queues or topics.","title":"Publishers"},{"location":"components/publishers/#publishing-to-a-queue","text":"Publishing a message to a queue makes this message available to a single consumer (that's the concept of a queue after all). To do that, build an instance of the QueuePublisher class and call the publish method with your message: from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = QueuePublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) The QueuePublisher requires a backend and a serializer as constructor parameters. The serializer is necessary to properly serialize and send the message to the messaging backend. TIP: In a production project where you would have a proper dependency injection framework in place (e.g. pinject ), you could instantiate the Publisher once and provide that instance through your application","title":"Publishing to a queue"},{"location":"components/publishers/#publishing-to-a-topic","text":"Publishing a message to a topic works exactly the same way as publishing to a queue, but it will work with the Fanout pattern to distribute the message to several subscribers of that topic. To do that, build an instance of the TopicPublisher class and call the publish method with your message: from melange.message_publisher import TopicPublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = TopicPublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-topic\" , message ) print ( \"Message sent successfully!\" ) As you can appreciate it works exactly the same way as publishing to a queue, the only difference happens behind the scenes.","title":"Publishing to a topic"},{"location":"components/serializers/","text":"Serializers Serializers are the component that translates (serializes) your python objects into a string that can be sent through the messaging infrastructure, and then translates it back (deserializes) that string back to the python object. Melange is bundled with two serializers: a JSONSerializer (to serialize python dictionaries and a PickleSerializer that will serialize any python object, but will only be deserializable from another python process and it's generally regarded as unsafe). When instantiating a publisher or a consumer you need to pass a list of serializers. Melange, upon sending or receiving messages, will select the serializer that best matches the one that can serialize and deserialize it. TODO: Implement the serializer selector from a list Creating your own serializers To create your own serializer, you need to inherit the class MessageSerializer and implement the methods manifest , deserialize and serialize . This is the MessageSerializer interface: MessageSerializer ( Generic ) Base interface to inherit for all the serializers of the platform Source code in melange/serializers/interfaces.py class MessageSerializer ( Generic [ T ]): \"\"\" Base interface to inherit for all the serializers of the platform \"\"\" def manifest ( self , data : T ) -> str : return \"\" def deserialize ( self , data : str , manifest : Optional [ str ] = None ) -> T : pass def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass serialize ( self , data ) Serializes and object to a string representation Source code in melange/serializers/interfaces.py def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass Some ideas of custom serializers: A protocol buffer serializer: Protocol Buffers (or protobuf for short) is a fast and compact serializing technology. In some projects where Melange is used in production such serializer has been implemented successfully.","title":"Serializers"},{"location":"components/serializers/#serializers","text":"Serializers are the component that translates (serializes) your python objects into a string that can be sent through the messaging infrastructure, and then translates it back (deserializes) that string back to the python object. Melange is bundled with two serializers: a JSONSerializer (to serialize python dictionaries and a PickleSerializer that will serialize any python object, but will only be deserializable from another python process and it's generally regarded as unsafe). When instantiating a publisher or a consumer you need to pass a list of serializers. Melange, upon sending or receiving messages, will select the serializer that best matches the one that can serialize and deserialize it. TODO: Implement the serializer selector from a list","title":"Serializers"},{"location":"components/serializers/#creating-your-own-serializers","text":"To create your own serializer, you need to inherit the class MessageSerializer and implement the methods manifest , deserialize and serialize . This is the MessageSerializer interface:","title":"Creating your own serializers"},{"location":"components/serializers/#melange.serializers.interfaces.MessageSerializer","text":"Base interface to inherit for all the serializers of the platform Source code in melange/serializers/interfaces.py class MessageSerializer ( Generic [ T ]): \"\"\" Base interface to inherit for all the serializers of the platform \"\"\" def manifest ( self , data : T ) -> str : return \"\" def deserialize ( self , data : str , manifest : Optional [ str ] = None ) -> T : pass def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass","title":"MessageSerializer"},{"location":"components/serializers/#melange.serializers.interfaces.MessageSerializer.serialize","text":"Serializes and object to a string representation Source code in melange/serializers/interfaces.py def serialize ( self , data : T ) -> str : \"\"\" Serializes and object to a string representation \"\"\" pass Some ideas of custom serializers: A protocol buffer serializer: Protocol Buffers (or protobuf for short) is a fast and compact serializing technology. In some projects where Melange is used in production such serializer has been implemented successfully.","title":"serialize()"},{"location":"examples/payment-service/","text":"Payment Service TODO","title":"Payment service"},{"location":"examples/payment-service/#payment-service","text":"TODO","title":"Payment Service"},{"location":"examples/saga/","text":"Saga TODO","title":"Saga choreography"},{"location":"examples/saga/#saga","text":"TODO","title":"Saga"},{"location":"tutorial/getting-started/","text":"Tutorial - Getting started This tutorial assumes that you have basic understanding of the pub/sub mechanics. If not, there are a whole bunch of resources to get your feet wet on the topic. Also it's good to have docker installed since we are going to spin up local infrastructure to serve as a messaging broker. Choosing a Messaging Backend A messaging backend is the infrastructure where your messages are going to be published and consumed. In this tutorial we are going to use ElasticMQ as our messaging backend. Basically spinning up an ElasticMQ (for example with docker-compose ) in your machine will provide you with an SQS-like infrastructure to use with boto, which makes it ideal for testing and for the sake of this tutorial. You could follow the instructions in the ElasticMQ project to install it to your local machine. Though the quickest route is to launch the docker image: docker run -p 9324:9324 -p 9325:9325 softwaremill/elasticmq-native This will start ElasticMQ in the port 9324 in localhost , ready to be used. Creating a queue Before using a queue you need to create it. Put the following code snippet into a file called create_queue.py and execute it to create the queue: from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.backends.factory import MessagingBackendFactory backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"melangetutorial-queue\" ) Publishing messages Publishing messages to a queue with Melange is easy. Just create an instance of the message publisher and publish the message. Put the following code snippet into a file called publish_example.py : from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = QueuePublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) Once you run this code it will publish a message MyTestMessage with the contents Hello World in the queue melangetutorial-queue . You can send anything as long as your selected serializer can serialize/deserialize the object. Refer Serializers for further details. NOTE: For the sake of this tutorial you can use the PickleSerializer to serialize your messages. For production applications however you should probably use another type of serializer or create your own, since pickle is considered unsafe and only works with python consumers. Consuming messages It's good to publish messages, but they are worth nothing if nobody reads them. Therefore, we need a consumer that reads these messages and reacts to them. Put the following code snippet in a file called consumer-example.py and run it: from melange.consumers import Consumer , ConsumerHandler from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer from publish_example import MyTestMessage class MyConsumer ( SingleDispatchConsumer ): @listener def on_my_test_message_received ( self , event : MyTestMessage ) -> None : print ( event . message ) if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () consumer = MyConsumer () consumer_handler = SimpleConsumerHandler ( serializer , backend = backend , ) print ( \"Consuming...\" ) payment_consumer . consume_loop ( \"melangetutorial-queue\" ) Upon hitting the consume_loop method, the process will start polling the queue for new messages. Once it receives a message, as long as the message is of type MyTestMessage it will forward this message to the MyConsumer . If your infrastructure was set correctly, every time you run the publish_example.py script you will see a print with the message on the screen where the consumer is running. Congratulations! You just run your very first example of a Pub/Sub mechanism with Melange! NOTE: It's a good idea to have shared classes (like the MyTestMessage in the example) in its own python module (e.g. shared.py ) Where to go from here Although the exposed example is quite simple, it serves as the foundation to implement a number of use cases and distributed architectures with microservices. With Melange you can: Build a CQRS + Event sourcing architecture, where you publish your events to a queue or topic from the Command side and read those with a consumer from the Read side to create your data projections. Build choreography Sagas for long-running processes which can span several transactions. Implement microservices which consume messages from a queue to do their job (e.g. an staticstics microservice that reacts to a OrderCreated event and increments a counter to track how many orders your system has). We have not covered the case of topics. Refer to Publishers for further details. In addition, Melange is bundled with a consumer that works with a python application. But the consumer can be implemented in any language and any technology that can read messages from your queue (AWS Lambda, Azure functions, a NodeJS app...)","title":"Tutorial - Getting started"},{"location":"tutorial/getting-started/#tutorial-getting-started","text":"This tutorial assumes that you have basic understanding of the pub/sub mechanics. If not, there are a whole bunch of resources to get your feet wet on the topic. Also it's good to have docker installed since we are going to spin up local infrastructure to serve as a messaging broker.","title":"Tutorial - Getting started"},{"location":"tutorial/getting-started/#choosing-a-messaging-backend","text":"A messaging backend is the infrastructure where your messages are going to be published and consumed. In this tutorial we are going to use ElasticMQ as our messaging backend. Basically spinning up an ElasticMQ (for example with docker-compose ) in your machine will provide you with an SQS-like infrastructure to use with boto, which makes it ideal for testing and for the sake of this tutorial. You could follow the instructions in the ElasticMQ project to install it to your local machine. Though the quickest route is to launch the docker image: docker run -p 9324:9324 -p 9325:9325 softwaremill/elasticmq-native This will start ElasticMQ in the port 9324 in localhost , ready to be used.","title":"Choosing a Messaging Backend"},{"location":"tutorial/getting-started/#creating-a-queue","text":"Before using a queue you need to create it. Put the following code snippet into a file called create_queue.py and execute it to create the queue: from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.backends.factory import MessagingBackendFactory backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) factory = MessagingBackendFactory ( backend ) factory . init_queue ( \"melangetutorial-queue\" )","title":"Creating a queue"},{"location":"tutorial/getting-started/#publishing-messages","text":"Publishing messages to a queue with Melange is easy. Just create an instance of the message publisher and publish the message. Put the following code snippet into a file called publish_example.py : from melange.message_publisher import QueuePublisher from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer class MyTestMessage : def __init__ ( self , message : str ) -> None : self . message = message if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () publisher = QueuePublisher ( serializer , backend ) message = MyTestMessage ( \"Hello World!\" ) publisher . publish ( \"melangetutorial-queue\" , message ) print ( \"Message sent successfully!\" ) Once you run this code it will publish a message MyTestMessage with the contents Hello World in the queue melangetutorial-queue . You can send anything as long as your selected serializer can serialize/deserialize the object. Refer Serializers for further details. NOTE: For the sake of this tutorial you can use the PickleSerializer to serialize your messages. For production applications however you should probably use another type of serializer or create your own, since pickle is considered unsafe and only works with python consumers.","title":"Publishing messages"},{"location":"tutorial/getting-started/#consuming-messages","text":"It's good to publish messages, but they are worth nothing if nobody reads them. Therefore, we need a consumer that reads these messages and reacts to them. Put the following code snippet in a file called consumer-example.py and run it: from melange.consumers import Consumer , ConsumerHandler from melange.backends.sqs.elasticmq import ElasticMQBackend from melange.serializers.pickle import PickleSerializer from publish_example import MyTestMessage class MyConsumer ( SingleDispatchConsumer ): @listener def on_my_test_message_received ( self , event : MyTestMessage ) -> None : print ( event . message ) if __name__ == \"__main__\" : backend = ElasticMQBackend ( host = \"localhost\" , port = 9324 ) serializer = PickleSerializer () consumer = MyConsumer () consumer_handler = SimpleConsumerHandler ( serializer , backend = backend , ) print ( \"Consuming...\" ) payment_consumer . consume_loop ( \"melangetutorial-queue\" ) Upon hitting the consume_loop method, the process will start polling the queue for new messages. Once it receives a message, as long as the message is of type MyTestMessage it will forward this message to the MyConsumer . If your infrastructure was set correctly, every time you run the publish_example.py script you will see a print with the message on the screen where the consumer is running. Congratulations! You just run your very first example of a Pub/Sub mechanism with Melange! NOTE: It's a good idea to have shared classes (like the MyTestMessage in the example) in its own python module (e.g. shared.py )","title":"Consuming messages"},{"location":"tutorial/getting-started/#where-to-go-from-here","text":"Although the exposed example is quite simple, it serves as the foundation to implement a number of use cases and distributed architectures with microservices. With Melange you can: Build a CQRS + Event sourcing architecture, where you publish your events to a queue or topic from the Command side and read those with a consumer from the Read side to create your data projections. Build choreography Sagas for long-running processes which can span several transactions. Implement microservices which consume messages from a queue to do their job (e.g. an staticstics microservice that reacts to a OrderCreated event and increments a counter to track how many orders your system has). We have not covered the case of topics. Refer to Publishers for further details. In addition, Melange is bundled with a consumer that works with a python application. But the consumer can be implemented in any language and any technology that can read messages from your queue (AWS Lambda, Azure functions, a NodeJS app...)","title":"Where to go from here"}]}